{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bf93dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13\n"
     ]
    }
   ],
   "source": [
    "# What verion of python\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001290aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/bin/python\n",
      "3.9.13 (main, Aug 25 2022, 18:29:29) \n",
      "[Clang 12.0.0 ]\n",
      "sys.version_info(major=3, minor=9, micro=13, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "# Anaconda details\n",
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294a3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run locally install the following packages\n",
    "# !pip install numpy==1.19.5 pandas==1.3.5 ipywidgets==7.7.0 \\\n",
    "#             matplotlib==3.5.2 seaborn==0.11.2 wordcloud==1.8.1 \\\n",
    "#             scikit-learn==0.24.2 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e8b67f",
   "metadata": {},
   "source": [
    "As there are problems with installing they will be dealt with as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245120f",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "#### Labeling\n",
    "\n",
    "In this course, our data is already labeled, so we'll perform a basic version of ETL (extract, transform, load) to construct the labeled dataset. However, labeling can be a time intensive process so it's very important to understand all its different facets so that we can have efficient labeling workflows. \n",
    "\n",
    "Start by loading our data assets that we'll be working on.\n",
    "\n",
    " * [projects.csv](https://github.com/GokuMohandas/Made-With-ML/blob/main/datasets/projects.csv): projects with id, created time, title and description.\n",
    " * [tags.csv](https://github.com/GokuMohandas/Made-With-ML/blob/main/datasets/tags.csv): labels (tag category) for the projects by id.\n",
    " \n",
    "**Objective** -  classify incoming content so that the community can discover them easily\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4cddc8",
   "metadata": {},
   "source": [
    "#### Extract\n",
    "\n",
    "Start by extracting data from our sources (external CSV files). Traditionally, our data assets will be stored, versioned and updated in a database, warehouse, etc. For now load our data as a stand-alone CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cf2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75546da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_on</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-20 06:43:18</td>\n",
       "      <td>Comparison between YOLO and RCNN on real world...</td>\n",
       "      <td>Bringing theory to experiment is cool. We can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-02-20 06:47:21</td>\n",
       "      <td>Show, Infer &amp; Tell: Contextual Inference for C...</td>\n",
       "      <td>The beauty of the work lies in the way it arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2020-02-24 16:24:45</td>\n",
       "      <td>Awesome Graph Classification</td>\n",
       "      <td>A collection of important graph embedding, cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-02-28 23:55:26</td>\n",
       "      <td>Awesome Monte Carlo Tree Search</td>\n",
       "      <td>A curated list of Monte Carlo tree search pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2020-03-03 13:54:31</td>\n",
       "      <td>Diffusion to Vector</td>\n",
       "      <td>Reference implementation of Diffusion2Vec (Com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           created_on                                              title  \\\n",
       "0   6  2020-02-20 06:43:18  Comparison between YOLO and RCNN on real world...   \n",
       "1   7  2020-02-20 06:47:21  Show, Infer & Tell: Contextual Inference for C...   \n",
       "2   9  2020-02-24 16:24:45                       Awesome Graph Classification   \n",
       "3  15  2020-02-28 23:55:26                    Awesome Monte Carlo Tree Search   \n",
       "4  19  2020-03-03 13:54:31                                Diffusion to Vector   \n",
       "\n",
       "                                         description  \n",
       "0  Bringing theory to experiment is cool. We can ...  \n",
       "1  The beauty of the work lies in the way it arch...  \n",
       "2  A collection of important graph embedding, cla...  \n",
       "3  A curated list of Monte Carlo tree search pape...  \n",
       "4  Reference implementation of Diffusion2Vec (Com...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract projects display the first 5\n",
    "PROJECTS_URL = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/projects.csv\"\n",
    "projects = pd.read_csv(PROJECTS_URL)\n",
    "projects.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aaf544",
   "metadata": {},
   "source": [
    "Load the labels (tag category) for our projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ba75b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>graph-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>graph-learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     tag\n",
       "0   6         computer-vision\n",
       "1   7         computer-vision\n",
       "2   9          graph-learning\n",
       "3  15  reinforcement-learning\n",
       "4  19          graph-learning"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract tags\n",
    "TAGS_URL = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/tags.csv\"\n",
    "tags = pd.read_csv(TAGS_URL)\n",
    "tags.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52659d18",
   "metadata": {},
   "source": [
    "#### Transform\n",
    "\n",
    "Apply basic transformations to create our labeled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5df8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_on</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-20 06:43:18</td>\n",
       "      <td>Comparison between YOLO and RCNN on real world...</td>\n",
       "      <td>Bringing theory to experiment is cool. We can ...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2020-02-20 06:47:21</td>\n",
       "      <td>Show, Infer &amp; Tell: Contextual Inference for C...</td>\n",
       "      <td>The beauty of the work lies in the way it arch...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2020-02-24 16:24:45</td>\n",
       "      <td>Awesome Graph Classification</td>\n",
       "      <td>A collection of important graph embedding, cla...</td>\n",
       "      <td>graph-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-02-28 23:55:26</td>\n",
       "      <td>Awesome Monte Carlo Tree Search</td>\n",
       "      <td>A curated list of Monte Carlo tree search pape...</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2020-03-03 13:54:31</td>\n",
       "      <td>Diffusion to Vector</td>\n",
       "      <td>Reference implementation of Diffusion2Vec (Com...</td>\n",
       "      <td>graph-learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           created_on                                              title  \\\n",
       "0   6  2020-02-20 06:43:18  Comparison between YOLO and RCNN on real world...   \n",
       "1   7  2020-02-20 06:47:21  Show, Infer & Tell: Contextual Inference for C...   \n",
       "2   9  2020-02-24 16:24:45                       Awesome Graph Classification   \n",
       "3  15  2020-02-28 23:55:26                    Awesome Monte Carlo Tree Search   \n",
       "4  19  2020-03-03 13:54:31                                Diffusion to Vector   \n",
       "\n",
       "                                         description                     tag  \n",
       "0  Bringing theory to experiment is cool. We can ...         computer-vision  \n",
       "1  The beauty of the work lies in the way it arch...         computer-vision  \n",
       "2  A collection of important graph embedding, cla...          graph-learning  \n",
       "3  A curated list of Monte Carlo tree search pape...  reinforcement-learning  \n",
       "4  Reference implementation of Diffusion2Vec (Com...          graph-learning  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join projects and tags\n",
    "df = pd.merge(projects, tags, on=\"id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9159a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove projects with no tag\n",
    "df = df[df.tag.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86234e22",
   "metadata": {},
   "source": [
    "#### Load\n",
    "\n",
    "Load our transformed data locally so that we can use it for our machine learning application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de3f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally\n",
    "df.to_csv(\"labeled_projects.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aff99d",
   "metadata": {},
   "source": [
    "### Exploration (EDA)\n",
    "\n",
    "Using Exploratory data analysis to understand the signals and nuances of our dataset. It's a cyclical process that can be done at various points of our development process (before/after labeling, preprocessing, etc. depending on how well the problem is defined. For example, if we're unsure how to label or preprocess our data, we can use EDA to figure it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945a2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "sns.set_theme()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73013dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAI1CAYAAAAgteCbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACTfUlEQVR4nOzdd1RT5/8H8PdNkKGCAiIgS8WBExeuunHVjbi3FkVr3dtq1YqrWvceKE5ARUXFKlptrXtU7VegLgRkiwwVBEny+8NDflKCYiS5jPfrnJ5D7vPc5B1JQz65zxAUCoUCRERERERElK8kYgcgIiIiIiIqilhsERERERERaQCLLSIiIiIiIg1gsUVERERERKQBLLaIiIiIiIg0gMUWERERERGRBrDYIiIiIiIi0gAWW0RERERERBrAYouIiCgPZDKZ2BE0oqg+LyKigoDFFhFRIeXn54fq1aur/Z+fn5/YT0FtGzZsQPXq1dGuXbtsx2/cuKF8flevXs23xztz5gxmzJih1rmfypR1fM2aNfkR84tdu3YNo0ePznH849dWWFiYCMmIiIoGFltERESfsHbtWkyePBnx8fFiR8lXhw8fxogRI/D8+XOxoxARFVk6YgcgIiL19OjRA506dVLZ1q1bN0RFRaFhw4bYsWOHyj56enqajCcKfX192NraKn/ODzExMV91viYy5YdPPa/SpUsrM5coUUJbkYiIihwWW0REhZSOjg50dFS/jQuCAACQSqUoVaqUNmOJytHREYGBgWLHyKYgZvqcjh07omPHjmLHICIq9DiMkIiIiIiISANYbBERFWOvXr3C5s2bMXjwYDRv3hy1a9dGw4YN0aVLFyxevPiz83muXbuGsWPHok2bNqhbty46deqEtWvXIjU1Fdu3b0f16tUxdOhQtbI9fvwYc+bMQYcOHVC3bl20a9cOS5cuRWJiYq7nfG6BjCtXrmDixIlo2bIlateujcaNG8PV1RXr1q3Dq1evsvXNWoTj2LFjAICbN28q7/vFixcAgNmzZ6N69eqYPn06IiMjMXr0aNSrVw9OTk4YMGAA4uPj87xox6tXr/Dzzz+jTZs2qFOnDtq1a4effvoJ4eHhKvtnPXarVq1yvU9VC11kHdu4cSMAIDIyUtnnxo0buZ73X5cuXcL48ePRokUL1K5dG02aNMHQoUNx6NAhvH//XuU5Q4cOVS4IIpfL4e3tjf79+6NRo0aoV68eevbsie3bt+Pdu3e5PiciosKEwwiJiIqpP/74A5MnT0Zqamq24+/fv8ebN2/w9OlTHD58GBs3blT5gX7FihXw9PTMduz58+fYsmULzpw5g5YtW6qd7ejRo/jpp5+QmZmpPBYZGQkvLy/89ttvaNq06Rff57p167B58+Zsx5KTk5GcnIz//e9/2L9/P3bt2oW6det+8X0nJydj6NChiIyMBACkpaUhKSkJZmZmePbs2WfPf/HiBXr16oXY2FjlscjISPj4+ODYsWNYsWIFunTp8sW5NCEtLQ3Tpk3DhQsXsh1PSkrCzZs3cfPmTRw8eBBbt26FlZWVyvt4//493NzccOXKlWzHQ0JCEBISgoCAAOzfvx+lS5fW2PMgItIGXtkiIiqGoqKiMGnSJKSmpqJixYpYs2YNzp8/j2vXruHo0aMYNmwYdHR0kJ6ejgULFkChUGQ7f+/evcpCq0WLFvD29sb169dx+PBhODs74/nz59i/f79a2W7cuIG5c+ciMzMT1apVw44dO3Dt2jUEBARg1KhRiIuLw4kTJ77oPv/++29lodW9e3ccOXIE165dw/nz57Fo0SKULl0aKSkpmDVrFuRyOQDA3d0dd+/eRffu3QEADRs2xN27d3H37t0cRcSff/6JuLg4LFy4EFeuXIGvry/mzJmT53ynTp1CXFwcRo0ahd9++w1Xr17F6tWrYW5ujoyMDMyYMQMhISFf9Jxz06NHD9y9exfu7u4AgAoVKiifV6NGjT57/tSpU5WFVufOneHj44MbN24gICAAY8aMgY6ODh49eoRRo0bhzZs3Ku/j4MGDuHLlCnr16gU/Pz9cv34dvr6+aNasGQAgODg4RyFPRFQY8coWEVExtH//fqSlpaFEiRLYuXMnbGxslG0mJiaoXbs2BEGAl5cXoqKi8PTpU1SpUgXAh6s4GzZsAAC0bt0aW7ZsgVQqBQAYGxtj06ZNmD59Ok6dOqVWtiVLlgAA7OzscPDgQRgaGipzzZo1CxYWFli6dOkX3ee5c+eU97ly5UrlAiImJiYYMGAA9PX1MWvWLDx79gzBwcGoVasWdHV1oaurq1yE5HOLjbi5uWHgwIEAgHLlyn3ZkwYwd+5cDBs2THm7a9euqFu3Lnr16oU3b95g9erV2L59+xff739lLayStcqgIAh5XkTl4sWL+P333wEAw4cPx9y5c5VtZcuWxbRp01CrVi1MmjQJz58/x+bNmzFz5swc95OWloaRI0di9uzZymPGxsbYtm0bOnTogNjYWAQGBmLixIlf81SJiETHK1tERMVQtWrV0L9/f4wePTpbofWxxo0bK3/+eJ7UhQsXkJKSAuBDgZBVaGURBAHz5s2Drq7uF+d6/Pgx/v33XwDA999/ryy0PjZs2DDY29t/0f1mZGQAAFJTU3MMmwSATp06YfPmzTh58iSqVq36xbmBD1d51FWtWrVshVYWGxsbDB8+HABw+fJlJCQkqP0Y+cHX1xcAYGpqiunTp6vs07lzZ+Vm076+vpDJZDn6CIKAMWPG5Diup6envLqVNS+OiKgwY7FFRFQM9erVCz///DMmTZqksj06OhpBQUHK2x/Pnfrrr78AAPb29qhYsaLK842NjbMVa3l1/fp15c+5LfwgCAKcnZ2/6H6zhsfFx8ejd+/e8PT0xNOnT5XtBgYGcHZ2RrVq1dQqEnV0dNQu0gCgQ4cOuba1bt0aACCXy3H37l21HyM/3Lp1CwDQtm3bT/47ZRWer1+/Vjn80draGiYmJirPzTqelpb2tXGJiETHYYRERMXY+/fvcfXqVYSEhOD58+eIiIjAkydPcqz49/GcraxFIOzs7D5535UrV1YWZnkVHR0N4MOmurl9GM+67y/RsWNHtG3bFhcvXsTz58+xYsUKrFixAhUqVECLFi3Qtm1btGjRQq1CKyvvf6/wfYlPPZ+P/52z/u3F8ObNG7x+/RoAPntl8eP26Oho1KpVK1u7sbFxrudm/Q7+O0+QiKgwYrFFRFRMHT58GJs2bVIWOFkkEglq1KiBihUr4syZMznOS0pKAvDhatCnlCxZ8oszZX2Y/9x9qxpe+ClSqRSbN2/GkSNH4O3tjYcPHwL4sFCIr68vfH19YWJigpkzZ8LFxeWLc+vp6X3xOR/71PP9+N9RzCXR3759q/z5c7/bj5/Px+dlyW0zbiKioobvdkRExdC+ffvg4eEBADA3N0fHjh1Ro0YNVKlSBVWrVkXJkiVx9epVlcWWvr4+AKic+/QxdYaBlSlTJk/3nTUH60tIJBL069cP/fr1Q0xMDC5fvoxr167hypUrSEpKwqtXrzB79myULl36k8P6NCE9PT3Xto9X9PvSIjM/i7OPC6zP/X6+pDAjIirKWGwRERUz7969w7p16wAAderUwb59+1ReWclt82A7OzuEhITkutltltw24/0US0tLAB8+rMfGxsLc3Fxlv4iIiC++749ZWFigb9++6Nu3L2QyGc6cOYM5c+YgIyMDe/fu1Xqx9anFID7ep8vW1lb5s0TyYdr1x/Pp/ivrKmR+KF26NIyMjJCSkpJtvpsqH7dXqFAh3zIQERU2XCCDiKiYefLkiXK4nouLS65D2K5du6b8OWvvKeD/VykMDQ3Nteh5+/Ytbty48cXZPl4U4/z587n2+/PPP7/ofidNmgRnZ2esXLkyR5tUKkW3bt3QokULAEBcXFy29qxl4jXp6tWrubZl/TuUKFEC9erVUx7PumKUkpKicsU/4MP+Yrn50uclCAIaNmwI4MMS8J+6unj27FllxmrVqn3R4xARFSUstoiIipmPF3J48uSJyj5XrlyBn5+f8vb79++VP3fv3h0lS5aEQqHAL7/8onIhgzVr1nx2qJkqNjY2ymJu8+bNiI2NzdHn7NmzuH379hfd77t37/DixQv4+/vj1atXOdozMjKUV2M+vnoE/P+/18f/Bvnt2rVryo2CPxYSEoKDBw8CALp06ZJtGGFWzvfv3yv3vvrYnTt3PrlASdbz+pIhmf369QMAJCQkYNWqVSr7nD9/HhcvXgTwoZjP2s+LiKg4YrFFRFTMVKtWDWZmZgAAb29vbN68GWFhYXj16hUePHgADw8PjBkzJtvVko8LpzJlymDChAkAPmwWPHbsWNy7dw9JSUkIDg7GzJkzsW/fPrXzLViwACVKlMDLly8xYMAABAQE4NWrV4iIiMDmzZsxbdq0L17577vvvgPw4arV8OHDce7cOURGRuLly5e4efMmxo4dqxwWOWTIkGznli1bFgDw77//4t69e0hMTMz3wksqlWLy5MnYsWMHIiMjER8fj8OHD2P48OFIT09Xbhj8sbZt2yr/HebNmwd/f3/Ex8cjPDwcO3bsgJub2yfneGU9r5cvX+LSpUtISkr65NwxAGjXrp1yDy0vLy9MnjwZ9+/fR3JyMp4+fYo1a9Zg8uTJAD4UzlOnTlXzX4SIqGjgnC0iomJGKpVi8eLF+OGHH5CZmYl169Yp53BlkUgkGDNmDPbu3Yt3797h+fPn2dpHjhyJ58+fw8fHB5cuXcKlS5eytdesWRO6urq4d+/eF688V6VKFWzbtg0TJkxAVFQUpkyZkq29bNmyGDJkCDZu3Jjn+2zcuDGmTZuG1atX49GjR8pi8WMSiQSTJk1S7muVpUmTJtixYwdSU1PRv39/AMDevXvRpEmTL3pen/L999/Dy8sLq1atynHFyMTEBNu3b88xf83GxgYTJkzA2rVrkZSUhBkzZmRrNzMzw7Jly+Dm5qbyMZ2cnCCVSiGTyeDu7g4AWLZsGXr37v3JrKtWrcL06dPx+++/48yZMyoXUalVqxbWrVuH0qVLf/a5ExEVZbyyRURUDLVt2xY+Pj749ttvYWZmBh0dHZQsWRKVK1dGnz59cOTIEUybNk05RycwMDDb+YIg4Oeff8amTZvQokULlC1bFiVKlEClSpUwceJEHDp0CKVKlQKg3rLo33zzDU6fPo3hw4ejUqVK0NPTg5mZGXr37o1jx4598T5bADBmzBgcOnQIPXr0gLW1NXR1daGnpwcbGxu4urri8OHDGDt2bI7zWrZsiZ9++gkVK1ZEiRIlYGJigpcvX37x439KlSpVcOzYMfTs2ROmpqbQ1dWFnZ0dRo0ahdOnT6NOnToqzxs3bhw8PT3Rtm1bGBsbZzvP39//kxstV6lSBatXr0a1atWgp6eHMmXK5LooysdKlSqFLVu2YPPmzXB2doaZmRlKlCiB8uXLo3nz5lixYgW8vb1hY2Oj9r8HEVFRISi4ayAREWlAv379cP/+fbi6umLp0qVixyEiItI6DiMkIqIvcuXKFZw8eRKVK1eGm5ubcgnyj6WlpSkXnFDnKhQREVFRwGKLiIi+iI6ODo4dOwbgwz5dzZo1y9Fnz549ys14s5ZUJyIiKm44jJCIiL7I+/fv0alTJ0RGRqJcuXKYOHEimjZtCkNDQ0RFReH48ePYv38/FAoFevXqhRUrVogdmYiISBQstoiI6Ivdv38fo0ePRnJycq59nJ2d8csvv3BFOiIiKrZYbBERkVoSEhKwd+9eXLp0CeHh4cjMzISZmRkcHBzQu3dvODs7QxAEsWMSERGJhsUWERERERGRBhT4fbZCQ0NRv359+Pn5KY8FBwdjyJAhqFevHtq0aYNdu3ZlO0cul2P9+vVo2bIlHB0dMWrUKISFhWk7OhERERERFWMFejXC9+/fY/r06UhNTVUeS0xMxMiRI9G+fXssWrQI9+7dw6JFi1C2bFm4uroCADZv3gxvb28sW7YM5ubmWLlyJUaPHo1Tp05BV1dXrSwKhQJyOS8CEhEREREVZxKJkOdh8gW62NqwYQNKlSqV7Zivry90dXWxcOFC6OjowN7eHmFhYdixYwdcXV2RkZEBT09PzJgxA61btwYArFmzBi1btkRgYCC6du2qVha5XIFXr95+9XMiIiIiIqLCy8SkFKTSvBVbBXYY4a1bt+Dj45NjyeDbt2/DyckJOjr/Xyc2bdoUoaGhSEhIQEhICN6+fYumTZsq242MjFCzZk3cunVLa/mJiIiIiKh4K5BXtlJSUjBz5kzMmzcPlpaW2dpiYmJQrVq1bMfKly8PAIiKikJMTAwA5DivfPnyiI6O/qpcOjoFtjYlIiIiIqICpkAWWwsXLkS9evXQvXv3HG3v3r3LMe9KT08PAJCeno60tDQAUNnnU/vBfI5EIsDYuNTnOxIREREREaEAFlvHjx/H7du3cfLkSZXt+vr6yMjIyHYsPT0dAFCyZEno6+sDADIyMpQ/Z/UxMDBQO5dcrkBKSurnOxIRERERUZFlZGQAqTRvI94KXLF19OhRJCQkoE2bNtmOL1iwALt27UKFChUQFxeXrS3rtrm5OTIzM5XHbG1ts/VxcHD4qmyZmfKvOp+IiIiIiIqPAldsrVq1Cu/evct2rGPHjpg4cSK6dOmC06dPw9vbGzKZDFKpFABw7do1VKpUCaampjA0NETp0qVx48YNZbGVkpKCoKAgDBkyROvPh4iIiIiIiqcCV2yZm5urPG5qagorKyu4urpi586d+PHHH+Hm5oYHDx7Ay8sLixYtAvBhrtaQIUOwatUqmJiYwMrKCitXroSFhQU6dOigzadCRERERETFWIErtj7H1NQUO3fuxJIlS+Di4gIzMzPMnDkTLi4uyj4TJ05EZmYm5s2bh3fv3sHJyQm7du1Se0NjIiIiIiKiLyUoFAqF2CEKA5lM/sWbGkskAiSSvG14Rtonlysgl/PlT0RERER592FT40K6QEZRIZEIKFu2ZJ5/EaR9MpkcSUmpLLiIiIiISCNYbGmIRCJAKpVg06EriIxTf38v0gyr8mUwfuA3kEgEFltEREREpBEstjQsMi4ZzyMTxY5BRERERERaxjFuREREREREGsBii4iIiIiISANYbBEREREREWkAiy0iIiIiIiINYLFFRERERESkASy2iIiIiIiINIDFFhERERERkQaw2CIiIiIiItIAFltEREREREQaoJOfd5aZmYlz584hJiYGdevWRaNGjfLz7omIiIiIiAoNtYutEydOYPPmzZg+fTo6dOgAuVyOkSNH4vbt28o+PXr0wIoVK/IlKBERERERUWGi1jDCK1euYNasWQgLC8PLly8BACdPnsStW7dQtmxZDBs2DHZ2dvD398fRo0fzNTAREREREVFhoFaxtW/fPgiCgI0bN2LgwIEAgNOnT0MQBCxcuBBz5syBt7c3SpUqxWKLiIiIiIiKJbWKrQcPHqB+/fpo3749ACA9PR3Xr19HiRIl0KZNGwBA2bJl0aBBAzx+/DjfwhIRERERERUWas3Zev36NcqXL6+8ffPmTWRkZKBJkybQ09NTHtfV1UVaWtrXpyQqpCQSARKJIHYMyoVcroBcrhA7BhERERVRahVblpaWiIqKUt7+448/IAgCWrRooTwml8sRHBycrSgjKk4kEgHGxgaQSKRiR6FcyOUyJCamseAiIiIijVCr2KpduzbOnDmDw4cPw8LCQjkvq1OnTgCAjIwMrF69GlFRUejVq1e+hSUqTD5c1ZIi9NQOpCVEix2H/sPA1BKVuo2GRCKw2CIiIiKNUKvYGj9+PK5du4affvoJAKBQKNCrVy/Y2toCAJydnfHy5UuULVsWY8eOzb+0RIVQWkI00mLDxY5BRERERFqmVrFlb28PX19fbNmyBS9fvoSTkxNGjhypbK9UqRIcHR0xa9Ys2NjY5FtYIiIiIiKiwkLtTY1tbGywdOlSlW1eXl4QBC4KQERERERExZdaS78PGzYM27Zty7U9q9BatmyZch4XERERERFRcaLWla2bN2/CwsLis/3+/fffbKsWEhERERERFRd5KramTp2K2NjYbMeuXLmCwYMH53rO69ev8fjxY1hbW39dQiIiIiIiokIoT8WWs7Mzpk2bprwtCAISEhKQkJDwyfOkUinGjx//dQmJiIiIiIgKoTwVW127doW5uTnkcjkUCgWGDx+Ob775Bu7u7ir7C4IAPT09WFtbw8TEJF8DExERERERFQZ5nrPVqFEj5c8uLi6oX78+GjdurJFQREREREREhZ1aC2QsW7YMABASEoJnz56hS5cuyrYHDx7gt99+Q/fu3VGjRo38SUlERERERFTIqLX0OwCsWbMGLi4uOZaADwkJgaenJ/r06YMdO3Z8dUAiIiIiIqLCSK0rWwEBAdi2bRtMTU3h6uqarc3Z2RmZmZnYvHkzVq9eDVtbW+61RURERERExY5aV7b27dsHAwMD+Pj4YNiwYdnaTE1NMWjQIBw6dAi6urrw8vLKl6BERERERESFiVrF1rNnz9CkSZNP7qFlY2ODRo0aITg4WO1wREREREREhZVaxZZCochTPz09PXXunoiIiIiIqNBTq9iyt7fHzZs38fLly1z7JCcn49atW7C3t1c7HBERERERUWGlVrHl6uqK1NRUuLm54X//+1+O9n///RdjxozBmzdv0Lt3768OSUREREREVNiotRphnz59cOHCBVy8eBF9+/aFqakpKlSoAACIiYlBfHw8FAoF2rZti4EDB+ZrYCIiIiIiosJArWILADZt2oS9e/fi0KFDCAsLyzak0MLCAkOGDMGoUaMgCEK+BCUiIiIiIipM1C62JBIJRowYgREjRiA2Nhbx8fGQyWQwMzNTXuUiIiIiIiIqrtQutj5mbm4Oc3Pz/LgrIiIiIiKiIkGtBTKyPH36FAsXLkSXLl1Qv359zJ49GwCwePFi7N+/P89LxBMRERERERU1al/ZOnr0KBYtWoSMjAzlMblcDgC4efMmDh48iFu3bmHNmjWQSL6qpiMiIiIiIip01KqC7ty5g/nz50NfXx8zZ87EqVOnsrVPmjQJ5ubmOHfuHPz9/fMlKBERERERUWGiVrG1Y8cOSCQS7Ny5E6NGjUKVKlWytbdv3x5eXl6QSqXw8fHJl6BERERERESFiVrF1t9//4369eujbt26ufaxs7ODk5MTwsLCvvj+ExISMGPGDDRt2hT169fHmDFj8OTJE2V7cHAwhgwZgnr16qFNmzbYtWtXtvPlcjnWr1+Pli1bwtHREaNGjVIrBxERERERkbrUKrbS0tJgZGT02X56enp4+/btF9//uHHjEBERgR07duDIkSPQ19fHiBEjkJaWhsTERIwcORIVK1bE0aNHMWHCBKxbtw5Hjx5Vnr9582Z4e3vDw8MDPj4+EAQBo0ePzja/jIiIiIiISJPUWiDDysoKQUFBkMlkkEqlKvu8f/8eQUFBX7znVmJiIqytrTFu3DhUrVoVAPD999+jZ8+eePz4Ma5duwZdXV0sXLgQOjo6sLe3R1hYGHbs2AFXV1dkZGTA09MTM2bMQOvWrQEAa9asQcuWLREYGIiuXbuq85SJiIiIiIi+iFpXtjp06ICYmBisWrUq1z6rV69GfHw8nJ2dv+i+jY2NsXr1amWh9fLlS+zatQsWFhaoUqUKbt++DScnJ+jo/H+d2LRpU4SGhiIhIQEhISF4+/YtmjZtqmw3MjJCzZo1cevWrS98pkREREREROpR68rW6NGjERAQgD179uD69etwcnICADx//hzr1q3D5cuX8fDhQ5ibm+O7775TO9z8+fPh6+sLXV1dbNmyBSVLlkRMTAyqVauWrV/58uUBAFFRUYiJiQEAWFpa5ugTHR2tdhYA0NHJe20qlXK5+8JAk78nvgYKB/6eiIiISFPUKrYMDQ2xb98+TJ8+HXfu3EFwcDAA4MGDB3jw4AEAoGbNmli9ejWMjY3VDjd8+HD0798fhw4dwvjx43Hw4EG8e/cOurq62frp6ekBANLT05GWlgYAKvskJyernUUiEWBsXErt86lgMjIyEDsCiYyvASIiItIUtTc1trS0xIEDB/DgwQNcv34d0dHRkMlkKF++PJycnNCkSZOvDpe1pPzixYtx79497N+/H/r6+jkWukhPTwcAlCxZEvr6+gCAjIwM5c9ZfQwM1P9QJZcrkJKSmuf+UqmEH+IKgZSUNMhkco3cN18DhYMmXwNERERU9BgZGeR5ZIzaxVaWunXrfnIJ+C+VkJCAa9eu4dtvv1UuviGRSGBvb4+4uDhYWFggLi4u2zlZt83NzZGZmak8Zmtrm62Pg4PDV2XLzOQHsqJGJpPz91rM8TVAREREmpKnkkwul0Mul+e4ndf/vkRcXBymTZuGmzdvKo9lrWxob28PJycn3LlzBzKZTNl+7do1VKpUCaampnBwcEDp0qVx48YNZXtKSgqCgoLQqFGjL8pCRERERESkrjxd2apVqxYEQcDp06dRqVIl1KpV64seRBAEmJiY4JtvvsHs2bM/OY/LwcEBLVq0wKJFi+Dh4QEjIyNs3boVKSkpGDFiBPT09LBz5078+OOPcHNzw4MHD+Dl5YVFixYB+DBXa8iQIVi1ahVMTExgZWWFlStXwsLCAh06dPii3EREREREROrKU7GlUCigUCiy3f4SCoUCL1++hL+/P96+fYuNGzfm2lcQBKxduxa//vorJk+ejNevX6NRo0Y4cOCAcs+unTt3YsmSJXBxcYGZmRlmzpwJFxcX5X1MnDgRmZmZmDdvHt69ewcnJyfs2rUrx6IZREREREREmiIovrRyUkNmZiaePn2K4cOHIz09HX///bemHzLfyWRyvHr1Ns/9dXQkMDYuhbnrAvA8MlGDyUgdFa2MsXRSFyQmvtXYfJ2s10CQ189Iiw3XyGOQ+gzMbVFz+E8afQ0QERFR0WNiUirPC2RoZYMZHR0dVK9eHVZWVl+1IiAREREREVFh8dWrEV6/fh03b95EfHw8dHV1YWpqisaNG6tcjGLJkiV48eLF1z4kERERERFRgad2sfXixQtMnjwZDx8+BPD/87gEQQAA1KhRA2vWrIGdnZ3yHAcHh69efp2IiIiIiKgwUKvYSk5OxrBhwxAVFQU7Ozt07NgR1tbWUCgUiIiIQGBgIIKCguDm5gY/Pz8YGhrmd24iIiIiIqICTa1ia8eOHYiKikK/fv2wYMEC5ebDWaZOnYqFCxfi8OHD2LNnDyZMmJAvYYmIiIiIiAoLtRbICAwMhIWFBX766acchRYASKVSLFiwABYWFjh79uxXhyQiIiIiIips1Cq2oqOj4ejoCB2d3C+M6ejowNHRkQtiEBERERFRsaRWsWVgYIDExM/vHZWYmAg9PT11HoKIiIiIiKhQU6vYql27Nu7evYugoKBc+wQHB+POnTuoXbu22uGIiIiIiIgKK7WKraFDhyIzMxPfffcdjh8/jtTUVGVbamoqjh8/Djc3N8jlcgwZMiTfwhIRERERERUWaq1G2KZNG7i5uWHnzp2YM2cO5s6di7Jly0IQBCQlJUEul0OhUOC7775D27Zt8zszERERERFRgaf2psbTp09HgwYNsGfPHvz999949eoVAKBEiRJo0KABRowYAWdn53wLSkREREREVJioVWzdu3cPDg4OaNeuHdq1aweZTIakpCQoFAqULVv2k6sUEhERERERFQdqVUVTp06FVCpFYGAggA/7apmamuZrMCIiIiIiosJMrQUy4uPj4eDgkN9ZiIiIiIiIigy1iq2qVasiJCQE79+/z+88RERERERERYJawwhXrFiBMWPGYMCAARg4cCCqVauGMmXKQCJRXbvZ2Nh8VUgiIiIiIqLCRq1ia/DgwXj//j1iYmIwf/78T/YVBOGTmx8TEREREREVRWoVW6VLl87vHEREREREREWKWsXW77//nt85iIiIiIiIihS1FsggIiIiIiKiT/uq3YdTU1MRGBiIGzduIC4uDjo6OrCwsEDLli3RunVrbm5MRERERETFltrV0OXLlzF37ly8fPkSCoUiW5uPjw8qV66MX375BbVq1frqkERERERERIWNWsVWUFAQfvjhB6Snp6N169Zo3749LC0toVAoEBUVhXPnzuHKlStwc3PDkSNHYGVlld+5iYiIiIiICjS1iq1NmzYhIyMDP//8M/r165ejvX///ti/fz88PDywdetWLF68+KuDEhERERERFSZqLZDx999/o3bt2ioLrSxDhgxBzZo18eeff6odjoiIiIiIqLBSq9h69+4dLC0tP9vPxsYGKSkp6jwEERERERFRoaZWseXo6IibN2/izZs3ufZ5//49Hjx4gNq1a6sdjoiIiIiIqLBSq9iaNWsWMjIy4O7ujtjY2BztqampmD17NhISEjB16tSvDklERERERFTYqLVAxpEjR1C7dm3cvHkTzs7OqF+/PipWrAiJRILY2Fjcvn0bb9++hYmJCVatWpXtXEEQsH///nwJT0REREREVFCpVWx9XCxlZmbi1q1buHXrVo5+CQkJSEhIyHZMEAR1HpKIiIiIiKhQUavY2rt3b37nICIiIiIiKlLUKrYaN26c3zmIiIiIiIiKFLUWyCAiIiIiIqJPY7FFRERERESkASy2iIiIiIiINIDFFhERERERkQaw2CIiIiIiItKAPBVb06dPx4EDBzSdhYiIiIiIqMjIU7F14cIF3L59W3m7Ro0amDVrlsZCERERERERFXZ5KrYEQcDjx4+RkZEBAFAoFFAoFBoNRkREREREVJjlaVPjWrVq4fbt22jSpAnKlCkDAAgMDESbNm0+e64gCLh48eJXhSQiIiIiIips8lRs/fjjjxg3bhyio6ORlpYGQRCQlpaGtLS0z54rCMJXhyQiIiIiIips8lRsOTg44OLFi4iPj0d6ejrat2+PDh06YPbs2ZrOR0REREREVCjlqdjKYmZmBgCoUKECrKysYGVlpZFQREREREREhZ1a+2z9/vvvGr2qlZSUhJ9++gmtWrVCgwYNMHDgwGyrIQYHB2PIkCGoV68e2rRpg127dmU7Xy6XY/369WjZsiUcHR0xatQohIWFaSwvERERERHRf33VpsYhISGYNWsW2rZti9q1a6N+/fro0KED5s2bh3/++Uft+506dSru37+P1atX48iRI6hVqxa+++47PH36FImJiRg5ciQqVqyIo0ePYsKECVi3bh2OHj2qPH/z5s3w9vaGh4cHfHx8IAgCRo8erVxNkYiIiIiISNO+aBjhx3x9ffHzzz8jMzNTeSwzMxMRERGIiIjA8ePHMW/ePAwYMOCL7jcsLAxXrlzBoUOH0KBBAwAfFuj4888/cerUKejr60NXVxcLFy6Ejo4O7O3tERYWhh07dsDV1RUZGRnw9PTEjBkz0Lp1awDAmjVr0LJlSwQGBqJr167qPmUiIiIiIqI8U+vK1v3797Fw4UJIpVL88MMPCAgIwIMHD/DgwQOcPn0a33//PaRSKTw8PL74CpexsTG2b9+O2rVrK48JggCFQoHk5GTcvn0bTk5O0NH5/zqxadOmCA0NRUJCAkJCQvD27Vs0bdpU2W5kZISaNWvi1q1b6jxdIiIiIiKiL6bWla0dO3ZAoVBg48aNaNmyZbY2e3t7TJw4EfXq1cOYMWOwZ88e/Prrr3m+byMjI+UVqSxnzpxBeHg4WrRogTVr1qBatWrZ2suXLw8AiIqKQkxMDADA0tIyR5/o6Og851BFRyfvtalU+lUjNElLNPl74mugcODviYiIiDRFrWLrzp07cHR0zFFofaxVq1aoV69etoUt1H2suXPnwtnZGe3atcOyZcugq6ubrY+enh4AID09Xbn3l6o+ycnJaueQSAQYG5dS+3wqmIyMDMSOQCLja4CIiIg0Ra1i6/Xr17CwsPhsPwsLCwQFBanzEACA8+fPY/r06XB0dMTq1asBAPr6+jkWukhPTwcAlCxZEvr6+gCAjIwM5c9ZfQwM1P9QJZcrkJKSmuf+UqmEH+IKgZSUNMhkco3cN18DhYMmXwNERERU9BgZGeR5ZIxaxVb58uURHBz82X7BwcEoV66cOg+B/fv3Y8mSJejQoQNWrVqlvFJlYWGBuLi4bH2zbpubmysX7IiLi4OtrW22Pg4ODmplyZKZyQ9kRY1MJufvtZjja4CIiIg0Ra3JCi1atEB4eDi2bNmSa5+tW7cq51l9qYMHD2Lx4sUYPHgw1q5dm21IoJOTE+7cuQOZTKY8du3aNVSqVAmmpqZwcHBA6dKlcePGDWV7SkoKgoKC0KhRoy/OQkREREREpA61rmyNHTsWp0+fxvr163Ht2jV07twZVlZWEAQBL168wNmzZ3Hz5k0YGhrC3d39i+47NDQUS5cuRYcOHeDu7o6EhARlm76+PlxdXbFz5078+OOPcHNzw4MHD+Dl5YVFixYB+DBXa8iQIVi1ahVMTExgZWWFlStXwsLCAh06dFDn6RIREREREX0xtYqtChUqwNPTExMmTMDNmzdzLKmuUChQvnx5rFu3DlZWVl9032fPnsX79+8RGBiIwMDAbG0uLi5Yvnw5du7ciSVLlsDFxQVmZmaYOXMmXFxclP0mTpyIzMxMzJs3D+/evYOTkxN27dqVY9EMIiIiIiIiTREUCoVC3ZMzMjIQEBCAW7duIS4uTllkOTk54dtvv822QEVhJ5PJ8erV2zz319GRwNi4FOauC8DzyEQNJiN1VLQyxtJJXZCY+FZj83WyXgNBXj8jLTZcI49B6jMwt0XN4T9p9DVARERERY+JSSnNLpCRRVdXF7169UKvXr2+5m6IiIiIiIiKHO7mSUREREREpAEstoiIiIiIiDSAxRYREREREZEGsNgiIiIiIiLSABZbREREREREGqBWsXXgwAHcvn07v7MQEREREREVGWot/b5x40YYGRnh7Nmz+Z2HiIiIiIioSFDrylZqaiqqVauW31mIiIiIiIiKDLWKrVatWuHGjRuIjIzM7zxERERERERFglrDCIcNG4bHjx+jR48ecHZ2RrVq1VCmTBkIgqCyf58+fb4qJBERERERUWGjVrE1dOhQCIIAhUIBf3//XIusLCy2iIiIiIiouFGr2OrVq9dnCywiIiIiIqLiTK1ia/ny5fmdg4iIiIiIqEjhpsZEREREREQa8FXF1tOnT7Fw4UJ06dIF9evXx+zZswEAixcvxv79+6FQKPIlJBERERERUWGj1jBCADh69CgWLVqEjIwM5TG5XA4AuHnzJg4ePIhbt25hzZo1kEh4AY2IiIiIiIoXtaqgO3fuYP78+dDX18fMmTNx6tSpbO2TJk2Cubk5zp07B39//3wJSkREREREVJioVWzt2LEDEokEO3fuxKhRo1ClSpVs7e3bt4eXlxekUil8fHzyJSgREREREVFholax9ffff6N+/fqoW7durn3s7Ozg5OSEsLAwtcMREREREREVVmoVW2lpaTAyMvpsPz09Pbx9+1adhyAiIiIiIirU1Cq2rKysEBQUBJlMlmuf9+/fIygoCBUqVFA7HBERERERUWGlVrHVoUMHxMTEYNWqVbn2Wb16NeLj4+Hs7Kx2OCIiIiIiosJKraXfR48ejYCAAOzZswfXr1+Hk5MTAOD58+dYt24dLl++jIcPH8Lc3BzfffddvgYmIiIiIiIqDNQqtgwNDbFv3z5Mnz4dd+7cQXBwMADgwYMHePDgAQCgZs2aWL16NYyNjfMvLRERERERUSGh9qbGlpaWOHDgAB48eIDr168jOjoaMpkM5cuXh5OTE5o0aZKfOYmIiIiIiAoVtYutLHXr1v3kEvBERERERETF0VcXWzdu3MDt27cRFxeHEiVKwMLCAo0bN2YBRkRERERExZraxdY///yDOXPm4OnTpwAAhUIBABAEAQDQoEEDrFixAtbW1vkQk4iIiIiIqHBRq9h6/vw5hg8fjtTUVDg4OKBNmzawtLSEQqFAZGQkAgMDcefOHQwbNgyHDx+GqalpfucmIiIiIiIq0NQqtjZu3IjU1FRMmDAB48ePz9E+ZcoULF26FPv378eGDRuwcOHCr81JRERERERUqKi1qfHVq1dRrVo1lYUWAEgkEvz444+ws7PDhQsXviogERERERFRYaRWsZWamorKlSt/so8gCHBwcEBKSopawYiIiIiIiAoztYqtGjVq4MGDB8jMzPxkv0ePHqFKlSpqBSMiIiIiIirM1Cq2pkyZgri4OMydOxdv3rxR2WfFihUICwvDhAkTviogERERERFRYZSnBTJmzpyZ41iFChVw8uRJ/PHHH2jVqhWsrKygp6eHuLg4XL16FeHh4XB0dMS///6LNm3a5HduIiIiIiKiAi1PxZa/v3+ubcnJyTh58qTKtnv37uH+/ftwd3dXLx0REREREVEhladia9myZZrOQUREREREVKTkqdhycXHRdA4iIiIiIqIiRa0FMoiIiIiIiOjT8nRlS5XY2Fj4+/sjPDwc6enpufYTBAErVqxQ92GIiIiIiIgKJbWKrZCQEAwaNAhpaWlQKBSf7Mtii4iIiIiIiiO1iq0VK1YgNTUVTk5OcHZ2hpGREQRByO9sREREREREhZZaxdbDhw9RqVIleHl5QSLhtC8iIiIiIqL/UqtSkkgksLe310qhtXnzZgwdOjTbseDgYAwZMgT16tVDmzZtsGvXrmztcrkc69evR8uWLeHo6IhRo0YhLCxM41mJiIiIiIiyqFUtffPNN3jw4AHevXuX33my2bNnD9avX5/tWGJiIkaOHImKFSvi6NGjmDBhAtatW4ejR48q+2zevBne3t7w8PCAj48PBEHA6NGjkZGRodG8REREREREWdQqtmbOnAm5XI6JEyfi+fPn+Rzpw0qHbm5uWLduHSpVqpStzdfXF7q6uli4cCHs7e3h6uqKESNGYMeOHQCAjIwMeHp6YsKECWjdujUcHBywZs0axMbGIjAwMN+zEhERERERqaLWnC1zc3O4u7tjyZIluHz5MvT09FC2bFmVfQVBwMWLF7/o/h8+fIgyZcrA398fmzZtQmRkpLLt9u3bcHJygo7O/0dv2rQptm3bhoSEBERGRuLt27do2rSpst3IyAg1a9bErVu30LVr1y97skRERERERGpQq9g6ceIEli5dCgBQKBR49+4dYmJiVPZVZ5XCdu3aoV27dirbYmJiUK1atWzHypcvDwCIiopS5rC0tMzRJzo6+ouzfExHJ+8XAqVSLhxSGGjy98TXQOHA3xMRERFpilrF1s6dO6FQKDB06FB0794dJiYmWlv6/d27d9DV1c12TE9PDwCQnp6OtLQ0AFDZJzk5We3HlUgEGBuXUvt8KpiMjAzEjkAi42uAiIiINEWtYis8PBz16tXDjz/+mN95PktfXz/HQhfp6ekAgJIlS0JfXx/Ah7lbWT9n9TEwUP9DlVyuQEpKap77S6USfogrBFJS0iCTyTVy33wNFA6afA0QERFR0WNkZJDnkTFqFVtGRkYwNTVV59SvZmFhgbi4uGzHsm6bm5sjMzNTeczW1jZbHwcHh6967MxMfiAramQyOX+vxRxfA0RERKQpak1WcHZ2xo0bN5CYmJjfeT7LyckJd+7cgUwmUx67du0aKlWqBFNTUzg4OKB06dK4ceOGsj0lJQVBQUFo1KiR1vMSEREREVHxpFaxNWXKFJQrVw7Dhg3D+fPnERcXh4yMDMjlcpX/5SdXV1e8efMGP/74I548eQI/Pz94eXnB3d0dwIe5WkOGDMGqVatw4cIFhISEYMqUKbCwsECHDh3yNQsREREREVFu1BpG+N1330GhUODJkyeYMGHCJ/sKgoCgoCC1wqliamqKnTt3YsmSJXBxcYGZmRlmzpwJFxcXZZ+JEyciMzMT8+bNw7t37+Dk5IRdu3blWDSDiIiIiIhIU9Qqtv73v//lua9CoVDnIZSWL1+e41jdunXh4+OT6zlSqRQzZszAjBkzvuqxiYiIiIiI1KVWsRUSEpLfOYiIiIiIiIoU7uZJRERERESkASy2iIiIiIiINECtYYTOzs557isIAs6fP6/OwxARERERERVaahVbkZGRn+0jCAKMjIwgCII6D0FEVGRIJAIkEr4XFkRyuQJy+dct5ERERJQbtYqtCxcuqDwul8uRlJSEu3fvYseOHahbty42btz4VQGJiAoziURAWWMDSCVSsaOQCjK5DEmJaSy4iIhII9QqtqysrHJts7GxQZ06ddC0aVP07t0bO3fuxJgxY9QOSERUmEkkAqQSKbb9sRdRybFix6GPVChjDvfWwyCRCCy2iIhII9QqtvKievXqcHJywtGjR1lsEVGxF5Uci7CEF2LHICIiIi3S6GqEJUuWRHR0tCYfgoiIiIiIqEDSWLEVFRWFGzduoFy5cpp6CCIiIiIiogJLrWGE69aty7VNLpcjISEBgYGBSE1NRd++fdUOR0REREREVFipVWxt2bIFgiBAofj0hOLatWvjhx9+UCsYERERERFRYaZWsfWpAkoQBJQqVQrVq1dH06ZNuc8WEREREREVS/lebBEREREREZGGVyMkIiIiIiIqrvJ0ZevatWtf9SDNmjX7qvOJiIiIiIgKmzwVWyNHjlR77pUgCAgKClLrXCIiIiIiosIqT8WWk5PTF91paGgoXr58CQCQSDhSkYiIijeJRIBEwgWjCiK5XAG5/NOrKxMRqStPxda+ffvydGcZGRlYu3Yt7ty5AwCoWLEili5dqn46IiKiQk4iEWBc1gASqVTsKKSCXCZDYlIaCy4i0gi1ViNU5f79+5gzZw5CQ0MhCAJGjhyJyZMnQ09PL78egoiIqNCRSARIpFLc27INb6KixY5DHyldwRL1xrlDIhFYbBGRRnx1sZWRkYE1a9Zg7969kMlkqFSpEpYtW4Z69erlQzwiIqKi4U1UNFLCwsSOQUREWvRVxdbff/+NuXPn4vnz55BIJPjuu+8wadIk6Orq5lc+IiIiIiKiQkmtYisjIwOrV6/Gvn37IJPJYG9vj2XLlqFu3br5nY+IiIiIiKhQ+uJi6+7du5gzZw7Cw8MhkUgwevRoTJgwgVeziIiIiHLBFSkLLq5ISZqU52IrPT0dv/76Kw4cOACZTIaqVati6dKlqFOnjibzERERERVqEomAsmVLQirldjgFkUwmR1JSKgsu0og8FVu3b9/Gjz/+iPDwcEilUowdOxY//PADdHTybTFDIiIioiJJIhEglUpwwvcGXsa/FjsOfaScmSF69mvCFSlJY/JULQ0dOlT5s7GxMW7duoXhw4fn6QEEQcD+/fvVS0dERERURLyMf43YqCSxYxCRFuWp2FIo/r/Sj4+PR3x8fJ4fQBA4PpmIiIiIiIqfPBVbe/fu1XQOIiIiIiKiIiVPxVbjxo01nYOIiIiIiKhI4bI4REREREREGsDlBImIiIiINIx7rRVcmtxrjcUWEREREZEGSSQCjMsaQCKVih2FVJDLZEhMStNIwcVii4iIiIhIgyQSARKpFAE+u/AqLlrsOPQRk/KW6NL/O43ttcZii4iIiIhIC17FRSMuKkLsGKRFXCCDiIiIiIhIA1hsERERERERaQCLLSIiIiIiIg1gsUVERERERKQBLLaIiIiIiIg0gMUWERERERGRBrDYIiIiIiIi0gAWW0RERERERBrAYouIiIiIiEgDWGwRERERERFpQJEttuRyOdavX4+WLVvC0dERo0aNQlhYmNixiIiIiIiomCiyxdbmzZvh7e0NDw8P+Pj4QBAEjB49GhkZGWJHIyIiIiKiYqBIFlsZGRnw9PTEhAkT0Lp1azg4OGDNmjWIjY1FYGCg2PGIiIiIiKgYKJLFVkhICN6+fYumTZsqjxkZGaFmzZq4deuWiMmIiIiIiKi4EBQKhULsEPnt3LlzmDBhAu7fvw99fX3l8UmTJuHdu3fYtm3bF9+nQqGAXJ73fypBACQSCZLfvINMJv/ixyPNkkolKFNaH3K5HJr6PyDrNfD+bQoUcplmHoTUJkikKFHKSKOvAeD/Xwcpaa+RyddBgaIjkcLIwFBrr4H0lBQoMvkaKEgEHSn0jLT3PvCWnwkKHKlUglIa/jwA/P9rIPVNCmQyvg8UJFKpFCVLf9n7gEQiQBCEPPXV+YpsBVZaWhoAQFdXN9txPT09JCcnq3WfgiBAKs3bP+rHypTW/3wnEo1EovmLuyVKGWn8MUh92ngNAICRgaFWHoe+nLZeA3pGfC8oqLT1GijFzwQFlrZeAyVL832goNLUa6BIDiPMupr138Uw0tPTYWBgIEYkIiIiIiIqZopksWVpaQkAiIuLy3Y8Li4OFhYWYkQiIiIiIqJipkgWWw4ODihdujRu3LihPJaSkoKgoCA0atRIxGRERERERFRcFMk5W7q6uhgyZAhWrVoFExMTWFlZYeXKlbCwsECHDh3EjkdERERERMVAkSy2AGDixInIzMzEvHnz8O7dOzg5OWHXrl05Fs0gIiIiIiLShCK59DsREREREZHYiuScLSIiIiIiIrGx2CIiIiIiItIAFltEREREREQawGKLiIiIiIhIA1hsERERERERaQCLLSIiIiIiIg1gsUVERERERKQBLLaIiIiIiIg0gMUWERERERGRBuiIHYCICi6FQoHr168jPj4ecrlcZZ9evXppNxQREWnNxo0bP9kuCAJ0dXVhZmaGevXqoWLFitoJRlqVkZGBJ0+eoGbNmgCABw8eYNeuXdDR0cGwYcPg6OgocsKCS1AoFAqxQxBRwRMWFobRo0cjIiJCZbtCoYAgCAgODtZyMioInjx5AqlUikqVKokdhTQsKirqk+1ZH7aNjY0hkXDATFHj4OAAQRAAfHjf/9h/jwuCgMGDB2PevHnaDUkaFR0djaFDh6JUqVI4ceIE4uLi0KlTJ6SlpQEAdHV1ceDAAdSpU0fkpAUTr2yRSh+/ueZGV1cX5cqVQ/369TFp0iTY2NhoKR1pw6pVqxAREQFXV1fUqVMHurq6YkcikXh7eyMkJAQLFy4EAEycOBGBgYEAgLZt22Lt2rV8fRRh7dq1++zfAwCQSqWoU6cOZs2ahXr16mk+GGmFr68vxowZAwsLC7i5uaFKlSrQ1dXFs2fPsHfvXvzzzz9YsGABdHR04O/vjwMHDqBGjRpwdXUVOzrlkw0bNiA2NhbTp08HABw/fhxpaWlYuXIl6tWrh1GjRmH79u3YsGGDyEkLJl7ZIpV+/PFHXLhwAUlJSbCzs0OVKlWgp6eHZ8+eISQkBPr6+qhevTqSkpIQFhaGMmXKwM/PD1ZWVmJHp3zi5OSE7t2746effhI7Cono2LFjmDNnDqpVqwZ/f39cunQJY8eOVQ4XOnHiBCZPngx3d3exo5KGbNq0Cfv27UNycjKaN28Oe3t75d+Dy5cvQyqVok2bNkhJScHt27cBAD4+PnBwcBA5OeWHqVOn4unTpzh8+HCOL1UyMzMxYMAA2NvbY8WKFQCAUaNG4e3bt/Dx8REjLmlAmzZt0LlzZ8yePRsAMGTIEDx//hx//fUXAGD79u3YvXs3rl27JmbMAotXtkilhg0b4vjx4/j111/RtWvXbG1Xr16Fu7s7hg0bhq5du+L+/fsYM2YMNm/ejCVLloiUmPJbZmYmatSoIXYMEpm3tzdq1aqFAwcOAADOnj0LHR0dbN68GSYmJhAEAadOnWKxVYTp6ekhPT0dBw8eRP369bO1PX78GAMHDkT9+vUxbNgwREVFYdCgQdi2bRvWrFkjUmLKT5cvX8b48eNVXr3W0dFB9+7dsWnTJuUxZ2dn/u6LmISEBFStWhUAkJaWhnv37qFjx47KdhMTE6SmpooVr8Dj4GpSadeuXejfv3+OQgsAmjdvjoEDB2Lr1q0AAEdHR/Tv3x9XrlzRdkzSoFq1auHhw4dixyCRPX78GL1794a+vj6AD1+21KpVCyYmJgCA+vXrIzw8XMyIpGHe3t4YPHhwjkILAKpWrYrBgwdj3759AIAKFSqgb9++uHXrlrZjkga9e/cu17bU1FS8f/9eeVsqlWojEmmRmZkZEhISAADXr19HZmYmmjdvrmx//PgxzMzMxIpX4LHYIpUiIiKU32KoUqlSJTx//lx529bWFq9evdJCMtKWiRMn4sSJEzh79myOSdFUfAiCgBIlSgAAnj17htjYWDRt2lTZnpaWBgMDA7HikRbEx8fD0tIy1/by5csjJiZGedvc3ByvX7/WRjTSAkdHR+zfvx+xsbE52hISEnDo0CHUrl1beeyvv/6Cra2tNiOShtWtWxeHDh3Cb7/9hrVr10JHRwdt27ZFZmYmzpw5g8OHD2f7u0DZcRghqWRhYYFr165h4MCBKttv3LiBcuXKKW/HxMTA1NRUW/FICzw9PVGmTBlMnjwZ+vr6MDY2zjFJXhAEnD9/XqSEpA0VK1bEzZs30a9fP5w8eRKCIKBly5YAPgw1DQgIgJ2dncgpSZNsbGxw/vx5DB48WGX777//jgoVKihvh4WF8VvuImTixIkYOnQovv32W7i4uKBSpUrKBTJOnTqFpKQk/PrrrwCAESNG4MaNG1yNsIiZNm0ahg0bhsmTJwMAvv/+e5iamuLatWuYMmUKKlSogHHjxokbsgBjsUUq9ejRA5s2bcLSpUsxduxY5ZCh169fw8vLC2fPnsWoUaMAALdv34aPjw+aNGkiZmTKZ48ePYJEIsn2jfZ/r3DxilfR17t3byxevBghISEIDQ1FpUqV0KhRIzx+/BjTp0/Ho0ePsGzZMrFjkgb1798fS5YswYQJE+Du7p7tw/aePXtw9epVTJkyBQBw4sQJeHt7o0uXLiKnpvxSt25d7Nq1CwsXLlTO3cxSsWJFrFy5Ek5OTnj58iXu3buHQYMG5fpFLRVONjY28Pf3x9WrV2FpaYm6desC+DCMeMqUKejbt6/ycyLlxNUISaXMzEyMHz8ef/zxBwRBgJGREXR1dZGQkAC5XI6mTZti69atkEgkqFevHvT19eHr64sqVaqIHZ2I8tmePXtw9OhRWFhYYO7cuahUqRKCg4MxdOhQjBkzBmPGjBE7ImnYokWLcOjQoRxXtxUKBVxcXLBkyRKkp6ejfv36KF++PHx8fD459JAKpydPniA0NBTv379HxYoVlRvcElHuWGzRJ/32228ICAjA8+fPlW+uXbp0Qbdu3SAIApKTk+Hr64tvv/0W1tbWYsclDVEoFEhMTISuri5Kly4tdhwqAGQyGWQyGffXKkb++ecflX8PGjRoAAB48+YN/vzzT7Rq1YrvE0RFTEZGBvbt24fAwEC8ePECa9euhYGBAfz8/JTDCkk1FltElKvExESsXLkS586dw9u3bwEApUuXRqdOnTB16lQOGyhGUlNTcfXqVYSHh0MqlaJixYpo3ry5cvEMIiq6wsPD4efnh5cvX0Imk+VoFwQBS5cuFSEZaUN6ejqGDx+Oe/fuQU9PDxkZGfD09ERycjImT54MOzs7HDx4kAVXLlhs0Selp6cjKSlJ5ZsrgGyToqloSUlJQd++fREWFqbc2Fomk+HZs2cIDw+HjY0Njh07xm+wi4HDhw/jl19+wZs3b5Tz9ARBgImJCRYtWoT27duLnJC0ITw8HPHx8ZDL5SrbnZyctJyItOHKlStwd3dHZmZmrn0EQUBwcLAWU5E2rVu3Dlu3boWHhwdat26NFi1aYPfu3WjatCm8vb3h4eGBwYMHY+7cuWJHLZC4QAap9PbtW3h4eODUqVO5vsEKgoCgoCAtJyNt2bJlC8LDw7F48WL07ds3W9uRI0cwf/58bNu2DdOmTRMpIWnD+fPnMX/+fFSoUAHu7u6oXLkyZDIZnj59iv3792Py5MnYu3evcigZFT0vX77ElClTcPv27U/244ftomnDhg0wMDDA/PnzUadOHQ4dLoYCAgLQs2dPuLq6IjExUXlcEAQMHDgQQUFBuHTpEoutXLDYIpXWrFmDY8eOoWLFiqhVqxbfXIuhwMBA9OzZM0ehBQB9+vTBnTt3cO7cORZbRdz27dtRuXJlHDlyBCVLllQe79ChAwYNGgRXV1ds2rQJu3btEjEladKvv/6KW7duoVmzZvywXQwFBwdj7Nix6NGjh9hRSCRRUVEYOXJkru1169bFiRMntJiocGGxRSqdPXsWLVq0wI4dO3KsPkXFQ0xMDOrVq5dru6OjI06fPq29QCSKx48fY9KkSdkKrSxGRkbo168ftm3bJkIy0pZLly6ha9euyr2UqHjR19dH2bJlxY5BIjI0NERCQkKu7eHh4TA0NNRiosJFInYAKpiSk5PRqVMnFlrFWJkyZRAVFZVr+4sXLzhfqxgoXbo0UlNTP9mHVzqKttTUVDRt2lTsGCSSZs2a4Y8//hA7BomoadOmOHz4MF6/fp2jLSIiAt7e3pyz+QkstkglOzs7xMbGih2DRNSkSRMcPHgQoaGhOdqePn2KQ4cOoXHjxiIkI23q3bs39u3bh4iIiBxtycnJ8Pb2Rp8+fURIRtpSpUoVle8DVDzMmDEDwcHBWLx4Me7du4cXL14gKioqx39UdE2YMAGvX79Gz549sX79egiCgAsXLsDDwwM9e/ZERkYGxo4dK3bMAourEZJK3t7eWL9+Pfz8/GBhYSF2HBLB06dP4erqCoVCgZ49e8Le3h6CIODx48fw9/eHIAjw9fVFtWrVxI5KGnTs2DFs2LABr169gouLC6pWrQpdXV2EhYXh6NGjSE1NxciRIyGVSpXnCIKA8ePHi5ia8tO5c+cwZ84c7NmzB3Xq1BE7DmlZ/fr1kZmZ+dnVCLlgVtH24MEDzJ07F0+ePMl23MrKCh4eHmjWrJlIyQo+Fluk0u7du3HgwAG8fPkSDRs2hJmZWY4hhdxXo+i7ffs25s6di/Dw8GzHbWxs4OHhgSZNmoiUjLTFwcHhi8/hMtBFi4eHBy5evIioqCjY2dnl+vfAy8tLpISkSbNnz87TlIJly5ZpIQ2J7d9//0VoaCjkcjmsra1Ru3ZtSCQcKPcpLLZIpbx8wOIHquJBoVAgKCgI4eHhUCgUsLW1Rc2aNfnmWkzcvHlTrfM4xLTo4N8DIiL1sdgilSIjI/PUz8rKSsNJiIiIiEhbNm7ciI4dOyqnCWzcuPGz53D4eO5YbBERAGDOnDkYMGAAHB0dlbc/h0NJi4/bt28jICAAL168gK6uLiwtLdG5c2c0bNhQ7GhElI+GDRuGcePGKefgDBs27LPncBhp0eLg4ICVK1eie/fuytufw6vbuWOxRQCAW7duwd7eHiYmJsrbecGlPosOvrlSbpYuXYp9+/bhv38uBEHA4MGDMW/ePJGSkSYcP34cjRo1grW1tfJ2XvTq1UtzoUhr+LeAbt68CXt7e5iamipv5wWHj6vGYosAqH5zzcuEWL65Fh2RkZEwMTGBgYGB8nZecChp0ebv74+ZM2eiSZMmmDhxIqpVqwaZTIbHjx9j48aNuHnzJn799Vd06dJF7KiUT77074FCoeCHbaIibM2aNWjVqhVHMqiJxRYByDk+d8OGDXkqtn744QdNRyMiEQ0YMAAZGRk4fPhwtuXdAUAmk6Ffv34wMDDA/v37RUpI+e3YsWNwcnJSXtk6duxYns5zcXHRZCwiEkn9+vUxbtw4jBkzRuwohZKO2AGoYPhv0TRhwgSRklBBkpCQgP/9739o3bo1AOD8+fPYunUrdHR08N1336FDhw4iJyRN+/fffzFhwoQchRYASKVSdO3aFZs3bxYhGWnKf4smFlGkUChw/fp1xMfHQy6Xq+zDYaRFV8mSJVX+DaC8YbFFn/T+/XuUKFECAJCSkoKTJ0+iRIkS+Pbbb2FoaChyOtKkJ0+eYNCgQShfvjxat26NsLAwTJ48GQBQokQJTJo0CTt37kTz5s3FDUqik8lkYkcgIg0JCwvD6NGjERERobI9axgpi62ia+rUqfjll19QqlQptG3bFmZmZtz+5Quw2CKV0tPTMWfOHERHR+PQoUN49+4d+vbtq9xraevWrfD29kb58uXFjkoasmnTJsjlckycOBHAh0nyMpkMXl5eqFWrFgYPHoxdu3ax2CriqlevjtOnT2P48OEqhxGeOnUKVatWFSkdaYNMJsOWLVtw+PBhJCQkqCyuBUFAUFCQCOlI01atWoWIiAi4urqiTp060NXVFTsSadmePXuQkZGBRYsWYdGiRSr78D0gdyy2SKWtW7ciICAAXbt2BQCcPHkSYWFhGDRoEGrVqoWlS5diy5YtWLBggchJSVNu3bqFoUOHomPHjgCAy5cvw9LSUrnaUK9evTh8rBgYNGgQZs6ciTFjxuCHH35AlSpVAEC5QEZwcDCWLFkickrSpE2bNmHz5s0wNDRE7dq1laMdqHi4fv06Bg4ciJ9++knsKCSSsmXLomzZsmLHKLRYbJFKZ8+eRadOnfDrr78CAC5evAgDAwPMnj0burq6CA0NRUBAgMgpSZOSk5NhY2MD4MMQ0qCgIPTs2VPZXqpUKbx//16seKQlPXr0wP3793HgwAFcvXo1W5tCoUD//v3Ru3dvkdKRNpw4cQKOjo7Ys2ePcrVSKj4yMzNRo0YNsWOQiPbt2yd2hEKNxRap9OLFC4wcORIAIJfLcevWLTRs2FA5fKBixYp4+fKlmBFJwywsLBAVFQUA+Ouvv6BQKPDNN98o2//55x8OIy0m5s+fj2+//RZnzpxBREQEFAoFbG1t0alTJ+6rUgzExcVhzJgxLLSKqVq1auHhw4fo27ev2FGoAEhLS0NMTAwsLCygp6fHuVt5wGKLVCpdujTS09MBAPfv38fr16+Vu8kDQHx8PC8pF3GNGzfGvn37YGBggAMHDkBfXx+tW7fG69ev4ePjAz8/PwwZMkTsmKQljRo1QqNGjcSOQSKwtLREcnKy2DFIJBMnToS7uzuaNWuGjh075mlbGCp6IiIi4OHhgStXrkAmk8HT0xOCIGDJkiVYuHAh9+D6BBZbpFK1atVw6tQpdOnSBbt374YgCGjTpg0AICYmBr6+vhxWUMRNmzYNwcHBWLlyJaRSKebPnw9DQ0PcunULq1atQo0aNeDu7i52TMpnt27dUus8JyenfE5CBUXv3r3h4+ODQYMGoXTp0mLHIS3z9PREmTJlMHnyZOjr68PY2DhHwSUIAs6fPy9SQtK06Oho9OvXD2/fvkWDBg2UfyfkcjlCQ0Ph5uaGQ4cOwcHBQeSkBROLLVLJ3d0d7u7u+Oabb6BQKNCmTRvY29vjzp07GDFiBIAPKxRR0WViYoIjR44gKCgIZmZmMDc3BwBUrVoVq1atQocOHaCnpydySspvQ4cOVeub6+DgYA2koYLA1tYWgiCgS5cuaNOmDczMzFR+2B4/frxICUmTHj16BIlEAktLS+UxhUKRrc9/b1PRsn79eqSnp+PYsWMwNjZWrkLcvHlzHDlyBMOHD8eWLVuwbt06kZMWTCy2SKVmzZph7969OHnyJCwsLDB06FAAgKmpKRo3boxx48bxknExIJFIULt27WzHypYti27duomUiDRt/PjxHCZE2UydOlX5s6+vr8o+LLaKrt9++43LvRdzly9fxsCBA2Fvb4/ExMRsbQ4ODhgwYACOHz8uTrhCgMUW5apevXqoV69etmMVK1bErl27xAlEGrVx40Z07NgR1apVU97+HH7AKnomTJggdgQqYPbu3St2BBJRr1690K9fP+WoFip+kpKSYGdnl2t7hQoVchRh9P9YbFGuMjIy8OTJE9SsWRMA8ODBA+zatQs6OjoYNmwYHB0dRU5I+Wnjxo2ws7NjsUXZvH37FqtWrcKlS5cQGxurcrgQN7Ms2q5cuYJWrVpxNEMxFRERgZIlS4odg0RkYWGBJ0+e5Np+7949rk78CSy2SKXo6GgMHToUpUqVwokTJxAXF4fhw4cjLS0NABAYGIgDBw6gTp06Iiel/LJ3717Y29tnu020YsUK+Pr6onz58qhXrx6kUqnYkUjL9u7di1KlSrHYKqYcHBxw584d9OvXT+woJJIOHTrA29sb3bp1U+6/mTXcPCAgAP7+/hg0aJCYEQs0Fluk0oYNGxAbG4vp06cDAI4fP460tDSsXLkS9erVw6hRo7B9+3Zs2LBB5KSUX/67X1K1atW4vD/h4sWLaN++PdavX8/9VIqpkiVLssguxkaOHIl58+YhLCwMbdq0Qbly5aCjk/PjY69evbQfjrTi+++/x6VLlzBo0CDY29tDEARs3LgRS5YswZMnT2BhYYFx48aJHbPAYrFFKl29ehWDBw/G8OHDAQB//vknypUrh+7duwMA+vbti927d4sZkTSsVatWaNeuHVxdXdGiRQsumlBMvXnzBq1bt2ahVYxNnToVv/zyC0qVKoW2bdvCzMyMr4diJGuBlHv37uHevXsAkO3vgUKhgCAILLaKMENDQ/j4+GDNmjUICAiAQqHA7du3UbJkSXTv3h3Tp0+HiYmJ2DELLBZbpFJCQgKqVq0K4MNu4ffu3UPHjh2V7SYmJkhNTRUrHmlB8+bNcf78eZw9exbly5eHi4sLevfuDVtbW7GjkRY1aNAADx8+RN++fcWOQiLZs2cPMjIysGjRIixatEhlH87bK7qWLVsmdgQqAIyMjLBgwQIsWLAAr169glwuh4mJCb94yQMWW6SSmZkZEhISAADXr19HZmamcl8FAHj8+DHMzMzEikdasHXrVrx69QonT57EiRMnsHXrVmzbtg2NGjWCq6srOnfuDH19fbFjkobNmDEDw4cPR6VKldClSxf+f18MlS1blkOKizEXFxexI1ABY2JiAplMhsuXL0MqlaJ58+Ysuj5BUHAnOlJh8uTJuH//PmbNmoUtW7bg6dOn+OOPP1CmTBkEBgbixx9/RJcuXeDh4SF2VNKSJ0+e4NixYwgICEBMTAxKliyJrl274ueffxY7GmnQ69evMX78eNy6dSvXPryqQVQ8yeVypKSk4PLly8ppBlT0KBQKrF69Gk+ePMGWLVsgk8kwePBg3L9/HwBQo0YN7N27F6VLlxY5acHEYotUioiIwLBhwxAdHQ3gw+TIiRMn4tq1axg5ciQqVKiAffv2wcrKSuSkpG0RERH45ZdfEBgYCEEQEBwcLHYk0qDZs2fj+PHjMDExgZ2dncqJ8QCwb98+LSejgiQ9PR16enpixyANSE1NxfLlyxEQEIDU1FSV2z8A4N+CImz37t1YsWIFGjdujL179yIgIABTp05F+/btUa1aNezYsQPDhw9XLqpG2XEYIalkY2MDf39/XL16FZaWlqhbty4AoGrVqpgyZQr69u3LyZDFSGJiIgICAnDixAn8888/AAAnJyf06dNH5GSkaRcvXoSzszPWrVuXa6FFRd+9e/dw+vRppKamQi6XK4/LZDKkpKTgzp07n7z6SYXXhg0blNs/WFpa4smTJ2jYsCHi4+MRFhYGAwMDzJ07V+yYpEEnTpxAs2bN4OnpCQA4f/48dHV1sWLFCpQqVQrJyckIDAxksZUL/uWkXBkaGqJTp07ZjpUrVw7u7u4iJSJtysjIwO+//44TJ07g8uXLyMzMhKWlJdzd3eHq6qrca4OKtoyMDLRp04aFVjF25swZTJ06VXlFQxCEbD9LJBLlF3JU9Jw/fx716tXDgQMHEBcXh7Zt22LRokWwt7fH2bNnMWXKFG4NUMSFhYVh4MCBylUor1+/DkdHR5QqVQrAh73YDh8+LGbEAo1/PSlXGRkZ2LdvHwIDA/HixQusXbsWBgYG8PPzw/fffw9TU1OxI5IGNW/eHG/fvkWJEiXQvn17LgFfTNWvX5+rERZzXl5eKFOmDFasWAG5XI7x48fjyJEjePfuHTw9PXH58mUsXLhQ7JikITExMRgyZAikUiksLS1RtmxZ3L9/H/b29ujUqRO+/fZb+Pr6onfv3mJHJQ3R1dVVXtEODg7Gq1evMHjwYGV7SkoKDA0NxYpX4HHpEFIpPT0dw4YNw8qVKxEcHIyEhAS8f/8eEREROHDgAAYNGqRcrZCKJmtra8ydOxeXL1/G2rVr0bJlSxZaxdC0adNw+vRpeHp6IjY2FjKZTOxIpGWPHz9G//790bp1a7Rq1Qo6OjqIjY1Fw4YNsX79elSqVAlbtmwROyZpiI6OjvIKBgDY2tri8ePHytuNGzdGRESEGNFISypXroyLFy8CAHx8fCAIAtq0aQPgw16Mfn5+sLe3FzFhwcZii1TaunUr7t+/jyVLluDChQvKISOdOnXCggUL8OLFC2zbtk3klKRJx48fx9ChQ1GmTBkAH1adioqKQkZGhsjJSJtmz54NiUSClStXok2bNqhduzZq1KiR7b+aNWuKHZM0KD09Xbm/nlQqha2tLf7991/l7e7duyvnclLRY2Njo/x9Z91+9OiR8vb79+/x9u1bMaKRlgwdOhSXL19Gw4YN4e3tDUdHR9SqVQv//PMPOnfujGfPnmHkyJFixyywOIyQVAoICEDPnj3h6uqKxMRE5XFBEDBw4EAEBQXh0qVLnBRbjLx69QrOzs7w9PREs2bNxI5DWsI9lsjU1BSvXr1S3ra2tsaTJ0+Ut8uUKYOXL1+KEY20wNnZGbt27YK1tTUGDRqEBg0aYPny5bh69SqqVauGw4cPw9raWuyYpEFdunSBjo4O/Pz8YGFhgQkTJgAA9PX1Ubp0acyZMwdt27YVOWXBxWKLVIqKivrktxR169bFiRMntJiICgLuFFH8cEl3atiwIY4cOYLevXvD1NQU9vb28Pf3R2pqKkqWLIm7d++yIC/C3NzccPnyZSxfvhwuLi5wcXGBp6cnvvvuO2Wfn376ScSEpA0dO3ZEx44dsx2rWrUqfvvtN5ESFR4cRkgqGRoafnJOVnh4OCdDEhEVA2PGjEFUVBScnZ3x6tUr9O7dGwkJCejTpw/c3Nxw/PhxtGjRQuyYpCGlSpWCj48PNm3aBCMjI5QsWRIHDx5E79690a5dOyxZsgQDBw4UOyZpUXJyMoYNG8bN7POIV7ZIpaZNm+Lw4cMYNmxYjraIiAh4e3vjm2++ESEZERFpk4ODA/bv34+dO3fCxMQEJiYmWL58ORYsWIBnz57ByckJ06ZNEzsmaZBUKkW7du2Ut83NzbFkyRIRE5GY3r9/j5s3byI5OVnsKIUCiy1SacKECejTpw969uyJ1q1bQxAEXLhwARcuXICfnx9kMhnGjh0rdkwiItICR0dHbNiwQXm7R48e6Ny5M969ewcjIyMRk5G2/PPPPwgMDERkZCTc3d1RsmRJPHz4EB07duRKtUSfICg4CYNy8eDBA8ydOzfbRGgAsLKygoeHBxdJKOIuXryIRo0aKYeLyuVyREdHw8zMDLq6uiKnIyIxhIaGIjIyErVq1YKBgQEkEgnfD4qBZcuWYe/evVAoFBAEAZ6ennj79i1++OEHODs7Y+3atShRooTYMUlLXr58iRYtWmD37t38LJgHvLJFuapbty5OnTqFf//9F6GhoZDL5bC2tkbt2rUhkXC6X1E3e/ZsuLq6YubMmQAAiUQCKysrkVMRkRju3buH+fPnK7988/T0hEKhwPTp0zF//nx8++23IickTTl27Bi8vLzQs2dPdOnSBe7u7gA+XO3s0qULzpw5gwMHDmDEiBHiBiUqoPiJmXKlUCjwxx9/oGLFiujcuTO6dOmC2NhY5cZ2VLRlZGTAzs5O7BhEJLLHjx9j5MiRePnyJXr06KE8bmBgAJlMhunTp+PWrVsiJiRN2r9/Pxo3bowVK1agbt26yuNmZmZYvXo1mjdvDj8/PxETkraVLFkSP/zwA2xsbMSOUiiw2CKV3rx5g2HDhmHs2LEIDQ1VHj916hR++OEHjBs3jpvbFnGurq7w8vLC06dPxY5CRCLasGEDSpYsiVOnTmHWrFnKLSDq168Pf39/mJmZYceOHSKnJE15+vQp2rdvn2t7+/btERERocVEJDYdHR2MGzeO+6vlEYcRkkrbt2/HnTt3MGbMmGz/M/30009wcHDAxo0bsWfPHowZM0bElKRJMpkMMTEx6NatG2xtbVGuXDlIpdJsfQRBgJeXl0gJiUgbbt68icGDB8PU1DTbJvfAh1Xp+vfvjwMHDoiUjjRNKpVCLpfn2p6SkpLjbwMVPUlJSVi/fj3OnTuHV69eYdeuXShRogR27tyJWbNmoVKlSmJHLLBYbJFKv/32G/r27YspU6ZkO25qaopx48YhMjISJ06cYLFVhB06dEj5c1hYGMLCwnL04QpUREXf27dvYW5unmt7mTJlkJKSosVEpE21a9fGmTNnVM7JSk9Px7Fjx1CjRg3tByOtSUpKQv/+/REWFgYbGxvl1e3k5GRcunQJDx48gI+PD4cV5oLDCEml2NhY1KpVK9f2unXr4sWLF1pMRNoWEhLy2f+Cg4PFjklEGmZtbY1//vkn1/br169z8ZwizM3NDQ8ePMD333+Pv/76CwAQGRmJc+fOYeDAgQgLC8Pw4cNFTkmatHHjRkRGRmL37t3w8fFRFlvOzs7Yvn07UlNTsXnzZpFTFly8skUqmZqa4t9//821/enTpyhTpowWExERkRi6deuGLVu2oGXLlnBycgLw4aq2XC7Hzp07ERgYqFyhjoqeli1bYt68eVi+fLlygaz58+cD+PA6mDhx4ifndFHh9/vvv6Nfv35o1qxZjqHErVq1Qv/+/REYGChSuoKPxRap1Lp1a/j4+MDZ2RnNmzfP1nb79m0cOnQo26pUVDRlZGRg3759CAwMxIsXL7B27VoYGBjAz88P33//PUxNTcWOSEQaNnr0aFy9ehWTJk2CkZERBEHAggULkJSUhOTkZDg4OLDYKuIGDx6M9u3b4+zZs3j+/DlkMhmsra3RsWNHrlpbDMTFxcHBwSHXdnt7exw8eFCLiQoXFluk0g8//IDAwEB89913cHBwQOXKlSEIAkJDQxEUFARTU1NMmDBB7JikQenp6Rg+fDju3bsHPT09ZGRk4P3793j58iUOHDiAv/76CwcPHmTBRVTE6erqYs+ePfDy8kJAQAAyMjIQHR0Na2trDBo0CKNHj4aBgYHYMUnDzM3NMWzYMLFjkAhMTU0RGRmZa/ujR49gbGysxUSFC4stUsnU1BR+fn749ddf8fvvvyvn5hgYGKBLly6YPn36JydMU+G3detW3L9/H0uWLEHr1q3RokULAECnTp2wYMECeHh4YNu2bZg7d67ISYlI00qUKAE3Nze4ubmJHYU0TN0907KGmFLR06pVK3h7e6Nv374oVapUtra7d+/C19cX3bp1EyldwScosma5EX1CUlISMjMzYWJiAomE66oUB506dUL9+vWxfPlyJCYmolmzZti9ezeaNWsG4MOY/Rs3buDcuXMiJyUiovzi4OCg1kqzXDCp6IqNjYWrqyvS09PRsGFD/PHHH+jYsSPS09Nx+fJllC5dGkePHuW+W7nglS36JIVCgf/973948eIFdHV1YWVl9clxu1R0REVFYeTIkbm2161bFydOnNBiIiLSBmdn5y8+RxAEnD9/XgNpSNvGjx/PbT0oG3Nzc3h7e+Pnn3/Gn3/+CYVCgbNnzwIAGjZsiAULFrDQ+gQWW5Sru3fvYs6cOQgPD8923NbWFkuWLEGjRo1ESkbaYGhoiISEhFzbw8PDYWhoqMVERKQN6gx44SCZooPzsUkVa2trbN++Ha9fv8bz588hl8thbW3Nedt5wGKLVHr69Cm+++47ZGZmwtXVFVWrVoVcLsejR49w6tQpjB49Gn5+ftwxvAhr2rQpDh8+rHJCdEREBLy9vfHNN9+IkIyINOn3338XOwIVYG/evMGSJUvg5uYGe3t7seOQlhkaGqJOnTpixyhUOGeLVJo2bRouXboEX1/fHG+mT58+Rf/+/dG+fXssX75cpISkaaGhoejTpw/KlCmD1q1bw9vbG4MHDwYA+Pn5QSaTwcfHh8NKiYqZzMxM/P3333BwcODV7WLo5cuXaNGiRbY5vFT0nTlzBpcuXUJsbCzkcnmOdkEQ4OXlJUKygo9Xtkila9euYeDAgSq/tbK3t0f//v1x8uRJEZKRtlSqVAm7d+/G3LlzcejQIQDA/v37AQBWVlbw8PBgoUVUDCUlJWHYsGHw9PTkh22iYsDT0xMrV6785HBhzvPLHYstUiklJeWTkx1tbGxy7CJORU/dunVx6tQp/PvvvwgNDVWO0a5duzZXpSQqxjgohqj48Pb2RvXq1bF69WrY2dlBKpWKHalQ4aclUsnCwgIPHjzItf3+/fsoX768FhORtm3cuBGPHj0CAFSvXh2dO3dGly5dULduXUgkEty/fx/z5s0TOSURERFpUmxsLAYOHIjKlSuz0FIDiy1SqX379jh+/DiOHz+eo83Pzw8nTpxAu3bttB+MtObjYkuVv//+m0u/ExVTHDJUfOnr68PFxYVfuBYjlStXRnx8vNgxCi0ukEEqpaSkwNXVFS9evICtrS2qVKkCQRDw+PFjhIeHw9LSEkePHoWxsbHYUSmfhIWFYfTo0ZDJZACAyMhImJiYwMDAIEdfhUKBuLg4WFlZKffaIKLigQskEBUvv/32GxYsWIDdu3ejZs2aYscpdFhsUa4SEhLw66+/IjAwEK9fvwYAlC5dGh06dMC0adNQrlw5kRNSfvPw8FAu+xwdHY2yZcuqLLakUilMTU0xadIkftgiKuZkMhlevHgBOzs7saOQhmRmZuLevXuIi4tDRkaGyj69evXSbijSqnHjxuGPP/6Ara0tzMzMclzd5mqEuWOxRSpdvHgRjRo1gqGhIRQKBRITE6FQKGBiYsLhI8WEg4MDVq5cie7du4sdhYhEVKNGDaxcuRLdunVT2X7kyBEsW7YMd+7c0XIy0oaIiAiMHDkSkZGRALIvjiIIAhQKBQRBQHBwsFgRScO2bNmCdevWfbIPXwO542qEpNLs2bPh6uqKmTNnQhAEmJiYiB2JtOzChQv8vRMVQ7Gxsbh27ZrytkKhwK1bt5CZmZmjr1wux8mTJ1Xuu0NFwy+//IKoqCj07NkTjo6O0NfXFzsSaZmPjw+qV6+OFStWoEqVKtDRYfnwJfivRSplZGRwSEgxJwgCEhMTP7vEf4UKFbSUiIi0wdjYGBs2bEBUVBSAD+8Fvr6+8PX1zdE36ypHjx49tJqRtOfGjRvo06cPfv75Z7GjkEhevXoFd3d37q2pJhZbpJKrqyu8vLzQqFEjlRsbU9HXrl27PA0Z5bABoqJFV1cXGzduREhICBQKBebOnYt+/fqhfv36OfpKJBKUK1cOTZs2FSEpaUNGRgbq1KkjdgwSUeXKlZGQkCB2jEKLxRapJJPJEBMTg27dusHW1hblypXLsbcCJ0MWbb169cpRbGVmZuLly5e4e/cubGxs0LdvX5HSEZEm1ahRAzVq1AAA3Lp1C66urnB0dBQ5FYmhTp06CAoKEjsGiWj06NH4+eef0aZNG9SuXVvsOIUOF8gglfJyqZiTIYuvsLAwDBw4ELNmzULPnj3FjkNERBpy+/ZtuLm5wcPDA126dIFEwi1ai5uslYqjo6NhY2ODcuXK5Zi3xS/gc8dii4jUsmHDBpw/f54bGxMVA+Hh4fDz88PLly+Ve/F9TBAELF26VIRklN+cnZ1zHIuPj8f79++hr6+PsmXL5ii4BEHA+fPntRWRtIxfwH8dDiMkIrVYWFggNDRU7BhEpGFXrlyBu7u7ytUIs7DYKjpUfQf/3301/9uH39sXbSEhIWJHKNRYbFGu0tLS4OnpiXPnziE8PBw6OjqoWLEiunXrhsGDB3Ppz2JMoVDgt99+g7GxsdhRiEjDNmzYAAMDA8yfPx916tSBrq6u2JFIg7I2tiei/MFPy6RSYmIiBg0ahNDQUBgaGqJSpUrIzMzE06dPsXz5cpw5cwZ79+7lH90ibM6cOSqPp6enIygoCGFhYRg6dKiWUxGRtgUHB2Ps2LFc3p0AfPh8oKOjA0NDQ7GjkIYcP34cjRo1grW1tfJ2XvTq1UtzoQoxFluk0tq1a/H8+XPMnTsXgwYNUl7FysjIwJ49e7B69Wps2bIFkyZNEjkpacqxY8dybStRogR69eqFKVOmaDEREYkha54OFV+xsbFYt24dzp8/j9evXwMATExM0LVrV0yYMIGFVxEze/ZsrFy5UllszZ49+5NbwSgUCgiCwGIrF1wgg1Rq2bIl2rZtm+smhrNnz8bt27c5IbYIi4yMVHlcR0cHxsbGvKpJVExMnjwZ7969w9atW8WOQiKIjIxE//798fLlS1SpUkU50iU0NBTPnz+HnZ0dfH19UaZMGbGjUj45duwYGjVqBBsbG+XtT8maz8ntYFTjlS1SKSUl5ZOrzzg6OuLMmTNaTETaZmVlJXYEIioAZsyYgUGDBmHx4sXo3r07ypUrp3L57woVKoiQjjRt9erVSE5OxqZNm3KsVBgQEICZM2diw4YNmDdvnkgJKb+5uLhkuz137lz88ssv6N69u8r+R44cwbJly1hs5YLFFqlUq1YtXL58GYMGDVLZfu/ePVSrVk3LqUgMx48fx7lz5xAREQGpVKpcJKV9+/ZiRyMiLejWrRsyMzNx8OBBHDx4UGUfQRC48W0RdfXqVQwZMkTlkvBdunTB3bt3ERgYyGKrCImNjcW1a9eUtxUKBW7fvq1y2we5XI6TJ09CLpdrM2KhwmKLVPrxxx8xYsQILFiwABMnToSpqSmA7CsUHjhwQOSUpEnp6elwc3PD7du3oVAoUKZMGchkMoSEhODs2bPo0KED1q1b98lx3ERU+HXq1In/nxdj7969U87dUaVy5cpITk7WYiLSNGNjY2zYsAFRUVEAPnyZ4uvrCx8fn2z9BEFQLvvPBXRyxzlbpFLHjh2RlJSknAibNUcnPj4ecrlcORnyY/xms2j59ddfsWPHDgwfPhzu7u4wMTEBAMTFxWHTpk3w9fXFrFmzMGLECHGDEhGRxowePRppaWnYt2+fyqJ73LhxSE9Ph6enpwjpSFOCg4MREhIChUKBuXPnol+/fqhfv36OfhKJBOXKlUPTpk0hlUpFSFrwsdgildRd0nvfvn35nITE0q5dOzg6OmLNmjUq27///ns8f/4cAQEBWk5GRGIJDQ1FZGQkatWqBQMDA0gkEi6WU8RFRERg+PDhqFq1KsaPH49q1apBR0cH4eHh2LVrF06fPo2tW7fC1tY223mcw1d0zJkzBwMGDICjo6PYUQolFltEpJKjoyNmz56NgQMHqmw/dOgQli9fjvv372s5GRFp27179zB//nw8efIEAODp6QmFQoHp06dj/vz5+Pbbb0VOSJpSq1YtAIBMJlNe2coaPpb1EZIjXYhyxzlblCfp6ek4c+YMWrRogXLlyokdh7TA3t4e9+/fz7XYevLkSY5vMomo6Hn8+DFGjhwJfX199OjRA/7+/gAAAwMDyGQyTJ8+HeXKlYOTk5PISUkTunfvzjl7RF+BxRblyevXrzFnzhx4enqy2Compk2bhrFjx6Jy5coYOXIkSpQooWw7fvw4Dh8+jC1btoiYkIi0YcOGDShZsiT8/f0hCAJOnDgBAKhfvz78/f3Rv39/7Nixg8VWEbV8+XKxIxAVaiy2KM844rR42bVrF4yNjbFmzRrs3LkTdnZ20NXVRVhYGBISEqCjo4Offvop2zmCIHCja6Ii5ubNmxg8eDBMTU2RmJiYrc3c3Bz9+/fn6rTFXExMDCwsLMSOQVQgsdgiIpWeP38OHR0dWFpaAgASEhIAALq6uspj/y3AWZATFT1v376Fubl5ru1lypRBSkqKFhORtp0+fRqnT59Gampqtv2UZDIZUlJS8OzZMzx8+FDEhEQFF4stIlLp999/FzsCERUA1tbW+Oeff9CvXz+V7devX4eVlZWWU5G2HDhwAB4eHtkWw/j4izU9PT0ukEL0CRKxA1DhIJFIUKFCBejr64sdhYiItKhbt244duwYzp07pzwmCALkcjm2b9+OwMBAdOrUScSEpElHjhyBpaUlTp8+jePHjwMA/vzzT/zxxx8YMmQI3r9/jwEDBogbkqgA49LvRJSrBw8e4NKlS4iNjc02dCSLIAhYunSpCMmISFsyMjIwcuRI3L17F0ZGRkhJSYGtrS2SkpKQnJwMBwcHHDp0CAYGBmJHJQ2oX78+xowZg3HjxkGhUKBBgwZYvny5ssAePHgwDA0NsXXrVpGTEhVMHEZIn/TPP/8gMDAQkZGRcHd3R8mSJfHw4UN07NiRS8EWcSdOnMCcOXNUFllZWGwRFX26urrYs2cPvLy8EBAQgIyMDERHR8Pa2hqDBg3C6NGjWWgVYZmZmShfvjyAD+/5tra2ePTokbLY6tixI/bs2SNiQqKCjcUW5WrZsmXYu3cvFAoFBEFAnz59EB4ejkmTJsHZ2Rlr167Nthw4FS3bt2+HhYUFFi1aBDs7O0ilUrEjEZFISpQoATc3N7i5uYkdhbSsfPnyiImJUd62trbG48ePlbcNDAzw6tUrMaIRFQqcs0UqHTt2DF5eXujRowe2bdumnAzr6OiILl264Pfff+dSv0VcZGQkRo0ahZYtW8LW1hZWVlYq/yMioqKrWbNm8Pb2RkhICADAwcEBN27cUBZYf/zxB0xNTcWMSFSg8coWqbR//340btwYK1asyLavipmZGVavXo3k5GT4+flhxIgR4oUkjbK0tMS7d+/EjkFEInvz5g1+/fVX5fxNVVO9BUFAUFCQCOlI09zd3XHu3Dm4uLjgypUr6NevH3bu3Ilvv/0WpqamCA0N5WcBok/glS1S6enTp2jfvn2u7e3bt0dERIQWE5G2DRs2DAcOHEBsbKzYUYhIRL/88gsOHToEmUyGevXqoVGjRjn+a9iwodgxSUNsbGzg5+eH4cOHw8TEBObm5ti6dSuMjIwQHx+Pnj17YuLEiWLHJCqweGWLVJJKpZ9cGCElJYVzeIq4gQMH4s8//0Tnzp3RoEED5QTpj3GBDKKi7+LFi2jfvj3Wr18PiYTf0RY3Fy9eRKNGjTB79mzlsWbNmiEwMFDEVESFB4stUql27do4c+aMyqEB6enpOHbsGGrUqKH9YKQ1Pj4+uHjxIgDgypUrKvuw2CIq+t68eYPWrVuz0CqmZs+eDVdXV8ycOVPsKESFEostUsnNzQ1jxozB999/r9wZPjIyEufOncPWrVsRFhaG6dOni5ySNMnT0xMVKlTAjz/+iCpVqkBHh28XRMVRgwYN8PDhQ/Tt21fsKCSCjIwM2NnZiR2DqNDipsaUqwMHDmD58uXIzMxULv8OfLiaMWHCBIwbN07khKRJdevWxcyZMzFkyBCxoxCRiEJCQjB8+HB8//336NKlC8zMzMSORFrk4eGBq1evYsOGDbC3txc7DlGhw6+qKVeDBw9G+/btcfbsWTx//hwymQzW1tbo2LEjv+UqBipUqIC0tDSxYxCRyKysrFC9enUsX74cy5cvV9mHqxEWXTKZDDExMejWrRtsbW1Rrly5HHO2BUGAl5eXSAmJCjZe2SIilfbv349du3bh0KFDsLCwEDsOEYlk9uzZOH78OExMTGBnZ5frkOJ9+/ZpORlpg4ODw2f7CIKA4OBgLaQhKnx4ZYtUOn78+Gf76OrqwszMDDVq1EDp0qU1H4q0Kj09HQDQuXNn1K9fH+XKlcvxIYsLZBAVfRcvXoSzszPWrVvHuZvFUNZmxkSkHl7ZIpUcHByUc7QAKDex/PhYFl1dXUyZMoWbGhYx/DaTiACgfv36mDt3LhfIKKY2btz4yXZBEJRfvtarVw8VK1bUTjCiQoLFFql06dIlzJ49Gzo6Ohg6dCjs7e2hp6eHZ8+ewdvbGzExMfjhhx+QmZmJgIAAPHr0CBs2bPjkRshUuERGRuapn5WVlYaTEJGYRo0aBVtbWyxcuFDsKCSCj798/e9Hxv8eFwQBgwcPxrx587QbkqgAY7FFKi1YsABXrlyBn58fjIyMsrW9ffsWrq6uaNGiBebNm4eMjAwMGTIE+vr62Lt3r0iJiYhIEx4+fIgRI0Zg3Lhx6Nq1q8oFEqjoevDgAcaMGQMLCwu4ubmhSpUq0NXVxbNnz7B37178888/WLBgAXR0dODv74/Lly/Dw8MDrq6uYkcnKhBYbJFKzZo1w8iRIzFmzBiV7Tt27MDu3btx9epVAICXlxc2b96MGzduaDMmacHx48dx5swZvHjxArq6urC0tETnzp3Ro0cPsaMRkRZ0794dcXFxSElJybUPVyMsuqZOnYqnT5/i8OHD0NXVzdaWmZmJAQMGwN7eHitWrADw4Uro27dv4ePjI0ZcogKHM11JpfT09E9+cymRSJCamqq8XbJkSWRkZGgjGmmJQqHAxIkTcf78eSgUChgaGkIulyM4OBgXL17Eb7/9hs2bN4sdk4g0rGzZsihbtqzYMUgkly9fxvjx43MUWgCgo6OD7t27Y9OmTcpjzs7OWLNmjTYjEhVoLLZIJQcHB/j6+mLAgAEoVapUtra0tDQcOXIEVatWVR67e/curK2ttR2TNGj//v0IDAxEjx49MG3aNJibmwMAoqOjsXbtWvj7++PQoUMYOHCgyEmJSJO4pDu9e/cu17bU1FS8f/9eeZtDTImyk4gdgAqmcePGISIiAt27d4enpycuXryIK1euYN++fejXrx+eP3+uHGI4b948nDhxAl27dhU5NeWno0ePonHjxvjll1+UhRYAWFpaYsWKFWjcuDGOHj0qYkIi0ra0tDSEhoYiLS0Ncrlc7DikBY6Ojti/fz9iY2NztCUkJODQoUOoXbu28thff/0FW1tbbUYkKtA4Z4tyFRAQgJ9//hlJSUnZVhwyMjLC3Llz0atXLyQlJaFp06Zo06YN1q5dC319fZFTU35xdHTE9OnTMXToUJXt+/btw5o1a3D37l0tJyMibYuIiICHhweuXLkCmUwGT09PCIKAJUuWYOHChWjYsKHYEUlDHjx4gKFDh0IqlcLFxQWVKlVSLpBx6tQpJCUlYffu3XBycsKIESNw48YNzJs3D4MHDxY7OlGBwGGElKsuXbqgffv2uHr1Kp4/f46MjAxUqlQJ33zzDUqWLAkAKFWqFP766y+UK1dO5LSU33R0dLLNy/uv1NRUlfuuEVHREh0djX79+uHt27do0KABbt26BQCQy+UIDQ2Fm5sbDh06lKe9+ajwqVu3Lnbt2oWFCxfiwIED2doqVqyIlStXwsnJCS9fvsS9e/cwaNAgDi8n+givbBGRSsOHD0dMTAz8/f2hp6eXrS0tLQ29evVC+fLlOZ+DqIibM2cOzp49i8OHD8PY2BjNmzfH7t270axZM4SEhGD48OFo2rQp1q1bJ3ZU0rAnT54gNDQU79+/R8WKFVGzZk2xIxEVeLyyRbmKjo7G2bNnkZqamm1svkwmw+vXr/HXX3/ht99+EzEhadKoUaPg7u6OPn36wN3dHVWqVAEAPH78GNu2bUN4eDhmzZolckoi0rTLly9j4MCBsLe3R2JiYrY2BwcHDBgwAMePHxcnHGlVlSpVlH8LiChvWGyRSteuXcPo0aMhk8mgUCggCEK2HeIBoHz58mJGJA1r3bo1Zs6cidWrV2PGjBnK4wqFAlKpFFOmTEG7du1ETEhE2pCUlAQ7O7tc2ytUqJCjCCMiog9YbJFK27ZtQ4kSJTB37lwAgIeHBzZt2oQ3b95g3759ePLkCQ4ePChyStK0UaNGoVWrVrh48SKioqKgUChga2uLpk2bcvgIUTFhYWGBJ0+e5Np+7949fvlGRJQLLv1OKgUFBaFfv34YNGgQ+vTpA4lEAh0dHfTo0QN79+5FuXLlsm1iSEXP+/fvMX36dHTv3h1t27bFggULsHDhQjx8+BCurq5YvHgxOOWTqOjr0KEDDh8+jAcPHiiPZY1wCAgIgL+/P9q2bStWPCKiAo3FFqmUmpqq3LRYV1cX1tbW+PfffwEABgYGcHFxwZ07d8SMSBq2Z88enDp1Cl26dIGJiYny+JgxY+Dq6oqDBw/C19dXxIREpA3ff/89LCwsMGjQIIwYMQKCIGDjxo3o3r07pk2bhvLly2PcuHFixyQiKpBYbJFKZcqUwZs3b5S3ra2t8fTpU+Xt8uXLIy4uToxopCXHjx9Hly5d8Ouvv2YrtqpXrw4PDw906tQJhw4dEjEhEWmDoaEhfHx80LdvX8TExEChUOD27duIjIxE9+7d4ePjk+09goiI/h/nbJFKjo6O8Pf3x8CBA6Gnp4dKlSrh4sWLkMlkkEqlePToEUqVKiV2TNKgyMhIDB8+PNf2Zs2a4Y8//tBiIiISi5GRERYsWIAFCxbg1atXkMvlMDExgUTC72yJiD6F75Kk0vDhwxESEoIOHTogKSkJ3bt3x4sXLzBy5EgsWLAABw8eRMOGDcWOSRpkaGiI8PDwXNujoqKgr6+vxUREJJbY2FisXLkSycnJMDExQbly5bBjxw4sW7aMKxESEX0Ciy1SqUmTJli3bh3KlSsHIyMj1K1bF1OmTMGtW7fg4+MDKysrTJ8+XeyYpEHNmzfHwYMH8fjx4xxtz58/x8GDB9G0aVMRkhGRNoWHh8PV1RWenp7ZvoCJiIiAl5cX+vbti/j4eBETEhEVXIKCy4nRF4iJiUFSUhKqVKkCHR2OQi3KwsLC4OLigszMTLRu3RqVK1cGAISGhuLy5cuQSCQ4fPiw8jgRFU3Tp0/HH3/8gbVr1+Kbb77J1nbnzh2MGzcOnTt3xs8//yxSQiKigovFFhHlKiQkBB4eHrhz5062Zd7r1auH+fPno1atWiKmIyJtaNWqFfr164cffvhBZfuaNWtw8uRJ/P7771pORkRU8PHSBKk0Z86cz/YRBAFLly7VQhoSi4ODA/bv34/ExERERUUhMzMT1tbWMDU1FTsaEWlJSkrKJ1cbtLCwwMuXL7WYiIio8GCxRSodO3Ys1zZBEKCrqws9PT0WW8WEsbExjI2NxY5BRCKwsbHBlStXMGjQIJXtN27cQIUKFbScioiocGCxRSpduHAhxzGZTIb4+HgcO3YM169fx8GDB0VIRkRE2tS9e3esWbMGa9asgZubGwwNDQEAb968wb59+3D27FmMHz9e5JRERAUT52yRWsaOHYsyZcpgxYoVYkchIiINyszMxKhRo3Dz5k1IJBKYmppCEAQkJCRAJpPByckJu3btgq6urthRiYgKHBZbpBZfX1+sXr0a169fFzsKERFpmEKhgJ+fH86fP48XL14o52+2b98erq6uXJ2WiCgXfHcktcTHx+Pdu3dixyAiIg07dOgQmjVrBldXV7i6uoodh4ioUGGxRSpFRUWpPP7u3Tv873//g5eXF5f9JiIqBlatWoURI0ZgwoQJYkchIip0WGyRSu3atYMgCLm2SySSXPdcISKiokMikXA1UiIiNbHYIpV69eqlstiSSqUoX748XFxcYGNjI0IyIiLSpu+++w7bt2+HnZ0dvvnmG0gkErEjEREVGlwgg4iIiHI1duxY3Lx5E2lpadDV1YWxsTGkUmm2PoIg4Pz58yIlJCIquHhli4iIiHL16NEjlC1bFmXLllUe++/3tPzelohINV7ZIpU+N2dLEATo6uqiXLlyqF+/PkaNGoUyZcpoMSERERERUcHGYotUGjFiBIKDg5GcnIySJUvC1tYWenp6CAsLQ1JSEkqUKIEyZcrg9evXSE9Ph5WVFY4ePZrtm08iIipaFAoFEhMToauri9KlS4sdh4iowOMsV1JpxIgReP36NaZOnYrr16/j+PHj8PHxwbVr17B48WIoFAr88ssvuHfvHlavXo1Xr15h8+bNYscmIiINSExMxNy5c+Hk5IRvvvkGTk5OcHJywrx58/Dq1Sux4xERFVi8skUqubq6wt7eHr/88ovK9h9//BGPHz+Gr68vAGDJkiW4ePEiJ0gTERUxKSkp6Nu3L8LCwmBnZ4cqVapAJpPh2bNnCA8Ph42NDY4dO8YrXUREKvDKFqn0+PFj1K9fP9f2OnXqICQkRHm7evXqiI+P10Y0IiLSoi1btiA8PByLFy/G2bNnsWnTJmzduhXnzp2Dh4cHXrx4gW3btokdk4ioQGKxRSqZmprif//7X67tDx8+hJGRkfJ2YmJitttERFQ0BAYGomfPnujbt2+Otj59+qBXr144d+6cCMmIiAo+FlukUocOHXDs2DF4eXlBJpNlazt27Bj8/PzQrl07AEBkZCQOHz6MOnXqiBGViIg0KCYmBvXq1cu13dHREdHR0doLRERUiHCfLVJp4sSJuH37NpYtW4ZNmzbB2toaurq6ytUIq1SpgqlTpyIzMxMdO3aEIAi5zu8iIqLCq0yZMoiKisq1/cWLF5yvRUSUC17ZIpVKly4Nb29vzJgxA7a2tggLC0NQUBDMzMwwadIkHD58GGXLlsXr16/Rt29f7N+//5PffBIRUeHUpEkTHDx4EKGhoTnanj59ikOHDqFx48YiJCMiKvi4GiERERHl6unTp3B1dYVCoUDPnj1hb28PQRDw+PFj+Pv7QxAE+Pr6olq1amJHJSIqcFhsERER0Sfdvn0bc+fORXh4eLbjNjY28PDwQJMmTURKRv/X3p0HVVk3bBy/bhYlSDulMiKIJVbEkvuCU/QImUtzyi3Fsk3H1Kwsp810dHLMTHMsdZyGGSUxcaGSmtSyRU20QG1UAsVlZNySwB3ZhHPeP3yf86jcmFnn3Ofo9/OX9+ZczDg6l78NgHejbMGUw+HQggULlJmZqRMnTtTZJEOSDMNQQUGBBekAAO6SlpamxMRERUVFXXbf6XSqoKBAhw4dktPpVGRkpGJiYuTnx4oEAKgPG2TA1Pz587VgwQI1atRIcXFxCgwMtDoSAMAD5s6dq8aNG7vKVnJyst555x0lJycrNjZWsbGxFicEAN9B2YKpr776Sm3bttWnn36qW265xeo4AAAP8fPz0y+//KLevXsrJCRER48eVUVFhdWxAMAnMY0QpuLj4zVp0iQNGTLE6igAAA969dVX9e2338owjGv+hmnlAGCOkS2YCgsL05kzZ6yOAQDwsGnTpiksLEx79+5VdXW1tm3bprvuuktNmjSxOhoA+BxGtmDqk08+UWZmpr766isOqwSAm1h0dLRmzZolu91udRQA8DmMbMFUZGSkDMNQ37599Z///EfNmjWrM6XEMAyNHTvWooQAAE9IT0+vszMhAODaMLIFU9HR0X/5jmEY2r17twfSAACsdujQIZWUlMjhcJg+79y5s4cTAYD3Y2QLptLT062OAADwAqWlpXrttde0bdu2q77Hf74BQF2ULZjq0qWL1REAAF5g9uzZ2rp1qxISEhQfH68GDRpYHQkAfAbTCHFVZ8+eVXl5+WXTRmpra3X27Flt2rRJo0ePtjAdAMDdEhIS1L17d82ePdvqKADgcxjZgqmTJ0/qjTfe0JYtW676HmULAG5s5eXl6tatm9UxAMAn+VkdAN5pzpw52rx5s+Li4tS9e3dJkt1uV7du3eTv76+goCClpqZanBIA4G5t2rTRwYMHrY4BAD6JsgVT2dnZSkxMVGZmpmbOnCmn06nnnntOaWlpWrJkiWpra3XgwAGrYwIA3GzUqFFasWKF8vLyrI4CAD6HaYQwVVJSohEjRkiSmjRpoqZNmyovL08xMTFq3769+vXrp6+//lrPPfectUEBAG6Vm5srm82mwYMHq1WrVvWeu7h48WKLEgKA96JswVSDBg3UsGFD13XLli21f/9+13V8fLzWrVtnRTQAgAd99tlnrl8XFRWpqKiozjtXli8AwEWULZhq3bq1duzYoSeeeELSxbK1Z88e1/Nz586purraqngAAA+59O9+AMDfw5otmOrTp4++/PJLTZ8+XZWVlerevbu2b9+uzMxM7dy5UxkZGbrzzjutjgkAAAB4Lc7ZgqmamhqNGzdOP/30k7Zv367AwEClpKSooKDA9c6cOXPUu3dvC1MCAP5tWVlZ6tSpkyIiIlzX16Jfv37uCwUAPoqyhavas2ePoqOjJUllZWVKT0/X6dOnlZSUxLkrAHADio6O1qxZs2S3213XV1uT5XQ6ZRiGdu/e7amIAOAzKFsAAMBl1apV6ty5s2tka9WqVdf0Xf/+/d0ZCwB8EmULkqStW7de13edO3f+l5MAAAAANwbKFiT99TSR+jBtBABuDsXFxdqwYYOOHj2qgQMHKjg4WMXFxYqLi7M6GgB4LbZ+hyRp7NixnJMCADCVnp6uDz/8UNXV1TIMQwkJCaqqqtKYMWP01FNPadKkSVZHBACvRNmCJOnll1+2OgIAwAutX79e06dPV9euXdW3b19NmTJF0sXzGNu3b6+lS5cqJiZGAwYMsDgpAHgfztnCNSkrK9OECRN04MABq6MAADxo4cKFiomJ0aJFi/TII4+47kdGRio9PV1xcXFatmyZhQkBwHtRtnBNKisrtWrVKv35559WRwEAeFB+fr4effRR+fv713kWEBCgxx9/XEVFRZ4PBgA+gLIFAACuqmHDhvU+q66uVk1NjQfTAIDvoGwBAIB63XPPPVq/fr3pM4fDoTVr1ujuu+/2cCoA8A2ULQAAUK9hw4Zp8+bNmjZtmmvdblVVlfLz8/Xiiy8qPz9fgwcPtjglAHgndiPENQkKClL//v0VGhpqdRQAgAfZ7Xbt2bNHCxcu1NKlSyVJY8aMkSQ5nU4NGjRIgwYNsjIiAHgtDjUGAAD1mjNnjhITExUYGKjVq1erqKhItbW1ioiIUK9evZSQkGB1RADwWoxsQZKUlZV1Xd/169fvX80BAPAu6enpCgkJ0QsvvKD777/f6jgA4FMoW5Akvf322zIMo97nlw6AGoYhp9MpwzAoWwBwgwsODjbd9h0A8NcoW5Akvf/++1ZHAAB4ofHjx2vmzJkKCQlRjx491KxZM/n5sb8WAFwL1mwBAIB62e12HTlyRJWVlfW+YxiGCgoKPJgKAHwDI1v42xwOh86ePatNmzbJbrdbHQcA4EY2m002m83qGADgkxjZgqny8nLNmDFDa9asUXl5uer7Y7J7924PJwMAAAB8A5OuYWrevHlauXKlgoODFRUVJUnq2LGjIiMj5XQ6FRQUpKlTp1qcEgAAAPBelC2Y+uGHH9SuXTutX79eqampcjqdevfdd/Xdd9/p448/VlVVFbtTAQAAAFdB2YKp48ePq0+fPvL391dYWJhsNpt27twpSerVq5f69OmjlStXWpwSAAAA8F6ULZgKCAhQSEiI6zoyMlL79u1zXXfp0kWHDx+2IhoAAADgEyhbMNWyZUsVFhZedr13717X9YULF3T+/HkrogEAAAA+gbIFU8nJyVqxYoUWL16sCxcuqEOHDsrNzdWWLVtUWlqqzMxMRUREWB0TAAAA8Fps/Q5T58+f17PPPqv8/Hzl5OQoICBAdrtdx44dc70zefJkDR061MKUAAAAgPeibKFetbW12rhxo5KSkiRJxcXFmjt3rk6fPq3k5GQNGDDA4oQAAACA96JswdScOXOUmJiojh07Wh0FAAAA8Ems2YKp9PR0bd++3eoYAAAAgM+ibMFUcHAwhxYDAAAA/wBlC6bGjx+v1NRULV++XMXFxXI4HFZHAgAAAHwKa7Zgym6368iRI6qsrKz3HcMwVFBQ4MFUAAAAgO8IsDoAvJPNZpPNZrM6BgAAAOCzGNkCAAAAADdgzRYAAAAAuAHTCGFqwoQJf/mOYRiaPn26B9IAAAAAvodphDAVHR1d7zPDMNSgQQM1bNhQubm5HkwFAAAA+A7KFkwdPXq0zr3a2lqVlJRo1apV+vXXX5WRkaHQ0FAL0gEAAADej7KF6zJ69Gjddttt+uCDD6yOAgAAAHglNsjAdUlKStLGjRutjgEAAAB4LcoWrktJSclVDzwGAAAAbnbsRghTx44dM71fWVmp33//XYsXL1ZsbKyHUwEAAAC+g7IFU0lJSTIMo97nfn5+eumllzyYCAAAAPAtlC2Y6tevn2nZ8vf3V2hoqPr376+WLVtakAwAAADwDexGCAAAAABuwAYZMPXMM8/ol19+qff5Dz/8oN69e3swEQAAAOBbmEYISVJFRYVOnTrlus7NzVXPnj3VqlWrOu86HA5lZ2fXu4kGAAAAAKYR4v+VlJSoV69eqqiokCQ5nc6rbpAhSe3atdOyZcs8EQ8AAADwOZQtuGRlZSknJ0dOp1NZWVnq1KmT6SYYfn5+atq0qYYOHarmzZtbkBQAAADwfpQtmEpKStLEiROVnJxsdRQAAADAJ1G2AAAAAMAN2CAD9aqoqNDmzZt1/vx5XdrJa2pqdO7cOWVnZ2vhwoUWJgQAAAC8F2ULpvLz8zVixAidOXPGde/KTTMCAwOtiAYAAAD4BMoWTM2bN09lZWUaPny4AgIClJqaqilTpuj06dP6/PPPdfLkSa1evdrqmAAAAIDX4lBjmNqxY4cGDBigN954Q6NGjZJhGGrdurXGjBmjzMxMhYSEKC0tzeqYAAAAgNeibMFUWVmZ4uLiJEnBwcFq0aKFdu/eLUm64447NHDgQG3evNnKiAAAAIBXo2zB1K233qoLFy64rlu2bKn9+/dfdn38+HErogEAAAA+gbIFU7GxsVq3bp3rOjIyUjt37nRdHz58WA0aNLAiGgAAAOATKFswlZKSopycHA0cOFDnzp1T7969tW/fPr355ptKTU3VkiVLXNMMAQAAANTFocao1+LFi/XJJ59o06ZNCggI0OTJk7Vy5UpJks1mU1pamu677z6LUwIAAADeibKFq3I4HPLz+98A6Pbt23Xq1Cl17NhRt99+u4XJAAAAAO9G2UK9ysrKtHbtWpWWlqq2trbOc8MwNHbsWAuSAQAAAN6PsgVTeXl5Gj58uMrKylTfHxHDMFzbwQMAAAC4XIDVAeCdPvroI1VWVuqVV15RfHw8Ow8CAAAAfxNlC6Z+++03Pf/88xozZozVUQAAAACfxNbvMOXv76+IiAirYwAAAAA+i7IFU+3bt9fWrVutjgEAAAD4LMoWTL3++uvasGGDFi1apJKSEqvjAAAAAD6H3Qhhym63q6SkRGfOnKn3HcMwVFBQ4MFUAAAAgO9ggwyYstlsstlsVscAAAAAfBYjWwAAAADgBqzZAgAAAAA3oGwBAAAAgBtQtgAAAADADdggAwBwU5g3b57mz5//t7758ccfOeAdAHDdKFsAgJvCvffeK7vdftm9EydOaMuWLQoODlZycnKdb4KDgz0VDwBwA2I3QgDATSsnJ0fPPPOMwsPD9dNPP1kdBwBwg2HNFgAAAAC4AWULAAATlZWVSktLU0pKirp06aLY2Fh169ZNI0eOVHZ2tuk3e/fu1bhx4/TAAw+oXbt2Gjp0qLKzs7VgwQLde++9+vLLLz38UwAArMSaLQAArlBVVaWnn35au3btUmhoqDp06CDDMFRYWKiff/5ZmzZt0vz58/Xwww+7vtm2bZtGjhyp8vJyxcbGqkOHDtqxY4dGjhyp2NhYC38aAIBVKFsAAFwhIyNDu3btUs+ePfXRRx8pIODiP5e1tbWaNm2aMjIytHTpUlfZqq6u1oQJE1ReXq4pU6boySeflHSxtL311ltau3atZT8LAMA6TCMEAOAKgYGBeuihhzR+/HhX0ZIkf39/DRkyRJJ05MgR1/2NGzfq0KFDSkxMdBUtSWrYsKHee+893XbbbZ4LDwDwGpQtAACuMGzYMKWmpqp169auexUVFdq1a5e+//57SRdHs/5ry5YtkmS6fXxISIgefPBBNycGAHgjphECAGCitLRUy5YtU05OjoqKilRaWiqn0ynDMCRJl56c8scff0iSwsLCTH+vFi1auD8wAMDrULYAALhCTk6ORo8erfLycoWFhalt27aKiopSTEyMwsPDNWjQoMvev3DhgqTLC9ilONISAG5OlC0AAC7hdDo1ceLEOptd/FdBQUGdb5o3by7pfyNcVzp+/Pi/HxQA4PVYswUAwCVKS0t1+PBhNW7cuE7RkuQ6Y8vhcLjude3aVZK0YcOGOu9XVVW51nQBAG4ulC0AAC7RqFEjBQYG6uzZs9q6detlz9atW6cFCxZIunyDjEceeUTNmzfXhg0b9MUXX7ju19TUaOrUqTpx4oQkudZ7AQBuDkwjBADgEkFBQUpJSdGSJUv07LPPqnPnzmrcuLH27dungwcPKjw8XKdOndK5c+dUWVmpoKAgBQUFacaMGRo5cqTeeecdZWRkKCIiQnl5eSouLlaLFi107Nixy7aRBwDc+BjZAgDgChMmTNDkyZPVpk0b7dq1S7m5uQoODtbo0aOVlZWlrl27yuFwaOPGja5vEhIStHz5cvXo0UOHDh3S+vXr1bx5c6WlpSk2NlbSxVEzAMDNw3CyRRIAAP/IiRMndPr0aYWHhysoKKjO88cee0yFhYVas2aNoqKiLEgIALACI1sAAPxDhYWF6tu3r0aMGHHZWi5JyszMVGFhoaKioihaAHCTYWQLAIB/qKamRikpKcrLy9Mdd9yhtm3bKjAwUAcOHNCBAwfUuHFjLVq0SPHx8VZHBQB4EGULAIB/wfnz57VixQp98803Onr0qCoqKhQaGqrExESNGDFC4eHhVkcEAHgYZQsAAAAA3IA1WwAAAADgBpQtAAAAAHADyhYAAAAAuAFlCwAAAADcgLIFAAAAAG5A2QIAAAAAN6BsAQAAAIAbULYAAAAAwA0oWwAAAADgBv8HwUmuW86Hw8QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of tags\n",
    "tags, tag_counts = zip(*Counter(df.tag.values).most_common())\n",
    "plt.figure(figsize=(10, 3))\n",
    "ax = sns.barplot(x=list(tags), y=list(tag_counts))\n",
    "plt.title(\"Tag distribution\", fontsize=20)\n",
    "plt.xlabel(\"Tag\", fontsize=16)\n",
    "ax.set_xticklabels(tags, rotation=90, fontsize=14)\n",
    "plt.ylabel(\"Number of projects\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a093c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural-language-processing', 388),\n",
       " ('computer-vision', 356),\n",
       " ('mlops', 79),\n",
       " ('reinforcement-learning', 56),\n",
       " ('graph-learning', 45),\n",
       " ('time-series', 31)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common tags\n",
    "tags = Counter(df.tag.values)\n",
    "tags.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc10242",
   "metadata": {},
   "source": [
    "The data imbalance will be dealt with after splitting into the train split and prior to training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7892c7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91775855a4d84acd87719250d7931e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='tag', index=3, options=('computer-vision', 'graph-learning', 'rein…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Most frequent tokens for each tag\n",
    "@widgets.interact(tag=list(tags))\n",
    "def display_word_cloud(tag=\"natural-language-processing\"):\n",
    "    # Plot word clouds top top tags\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    subset = df[df.tag==tag]\n",
    "    text = subset.title.values\n",
    "    cloud = WordCloud(\n",
    "        stopwords=STOPWORDS, background_color=\"black\", collocations=False,\n",
    "        width=500, height=300).generate(\" \".join(text))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96311c1",
   "metadata": {},
   "source": [
    "Looks like the title text feature has some good signal for the respective classes and matches our intuition. We can repeat this for the description text feature as well. This _information_ will become useful when we decide how to use our features for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78263f6",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Preprocessing the data via feature engineering, filtering and cleaning. Certain preprocessing steps are global (don't depend on our dataset, ex. lower casing text, removing stop words, etc.) and others are local (constructs are learned only from the training split, ex. vocabulary, standardization, etc.). For the local, dataset-dependent preprocessing steps, we want to ensure that we split the data first before preprocessing to avoid data leaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f0753",
   "metadata": {},
   "source": [
    "#### Feature engineering\n",
    "\n",
    "Combine existing input features to create new meaningful signal (helping the model learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8e51699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df[\"text\"] = df.title + \" \" + df.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c1280a",
   "metadata": {},
   "source": [
    "#### Cleaning\n",
    "\n",
    "Dealing with text data, apply some of the common text preprocessing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8370abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk==3.7 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a696820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4df712f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alwinsolair/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fe41a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, lower=True, stem=False, stopwords=STOPWORDS):\n",
    "    \"\"\"Clean raw text.\"\"\"\n",
    "    # Lower\n",
    "    if lower: \n",
    "        text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    if len(stopwords):\n",
    "        pattern = re.compile(r'\\b(' + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
    "        text = pattern.sub('', text)\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(\n",
    "        r\"([!\\\"'#$%&()*\\+,-./:;<=>?@\\\\\\[\\]^_`{|}~])\", r\" \\1 \", text\n",
    "    )  # add spacing between objects to be filtered\n",
    "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
    "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
    "    text = text.strip()  # strip white space at the ends\n",
    "\n",
    "    # Remove links\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Stemming\n",
    "    if stem:\n",
    "        text = \" \".join([stemmer.stem(word, to_lowercase=lower) for word in text.split(\" \")])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "274c1557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc4b446da5e4d05855a1f027a342cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='lower'), Checkbox(value=False, description='stem'), Ou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Toggle preprocessing parameters\n",
    "@widgets.interact(lower=True, stem=False)\n",
    "def display_cleaned_text(lower, stem):\n",
    "    text = \"Conditional image generation using Variational Autoencoders and GANs.\"\n",
    "    cleaned_text = clean_text(text=text, lower=lower, stem=stem)\n",
    "    print (cleaned_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffafab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between YOLO and RCNN on real world videos Bringing theory to experiment is cool. We can easily train models in colab and find the results in minutes.\n",
      "comparison yolo rcnn real world videos bringing theory experiment cool easily train models colab find results minutes\n"
     ]
    }
   ],
   "source": [
    "# Apply to dataframe\n",
    "original_df = df.copy()\n",
    "df.text = df.text.apply(clean_text, lower=True, stem=False)\n",
    "print (f\"{original_df.text.values[0]}\\n{df.text.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1a29d",
   "metadata": {},
   "source": [
    "### Replace labels\n",
    "\n",
    "Based on our findings from EDA, we're going to clean up our label space:\n",
    "\n",
    "   * if a data point has a tag that we currently don't support, we'll replace it with **other**\n",
    "   * if a certain tag doesn't have enough samples, we'll replace it with **other**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57cf4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepted tags (external constraint)\n",
    "ACCEPTED_TAGS = [\"natural-language-processing\", \"computer-vision\", \"mlops\", \"graph-learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f233ebed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reinforcement-learning', 'time-series']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of scope (OOS) tags\n",
    "oos_tags = [item for item in df.tag.unique() if item not in ACCEPTED_TAGS]\n",
    "oos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97501276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_on</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-02-28 23:55:26</td>\n",
       "      <td>Awesome Monte Carlo Tree Search</td>\n",
       "      <td>A curated list of Monte Carlo tree search pape...</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>awesome monte carlo tree search curated list m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>121</td>\n",
       "      <td>2020-03-24 04:56:38</td>\n",
       "      <td>Deep Reinforcement Learning in TensorFlow2</td>\n",
       "      <td>deep-rl-tf2 is a repository that implements a ...</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>deep reinforcement learning tensorflow2 deep r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>218</td>\n",
       "      <td>2020-04-06 11:29:57</td>\n",
       "      <td>Distributional RL using TensorFlow2</td>\n",
       "      <td>🐳 Implementation of various Distributional Rei...</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>distributional rl using tensorflow2 implementa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>239</td>\n",
       "      <td>2020-04-06 18:39:48</td>\n",
       "      <td>Prophet: Forecasting At Scale</td>\n",
       "      <td>Tool for producing high quality forecasts for ...</td>\n",
       "      <td>time-series</td>\n",
       "      <td>prophet forecasting scale tool producing high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>277</td>\n",
       "      <td>2020-04-07 00:30:33</td>\n",
       "      <td>Curriculum for Reinforcement Learning</td>\n",
       "      <td>Curriculum learning applied to reinforcement l...</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>curriculum reinforcement learning curriculum l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           created_on                                       title  \\\n",
       "3    15  2020-02-28 23:55:26             Awesome Monte Carlo Tree Search   \n",
       "37  121  2020-03-24 04:56:38  Deep Reinforcement Learning in TensorFlow2   \n",
       "67  218  2020-04-06 11:29:57         Distributional RL using TensorFlow2   \n",
       "74  239  2020-04-06 18:39:48               Prophet: Forecasting At Scale   \n",
       "95  277  2020-04-07 00:30:33       Curriculum for Reinforcement Learning   \n",
       "\n",
       "                                          description                     tag  \\\n",
       "3   A curated list of Monte Carlo tree search pape...  reinforcement-learning   \n",
       "37  deep-rl-tf2 is a repository that implements a ...  reinforcement-learning   \n",
       "67  🐳 Implementation of various Distributional Rei...  reinforcement-learning   \n",
       "74  Tool for producing high quality forecasts for ...             time-series   \n",
       "95  Curriculum learning applied to reinforcement l...  reinforcement-learning   \n",
       "\n",
       "                                                 text  \n",
       "3   awesome monte carlo tree search curated list m...  \n",
       "37  deep reinforcement learning tensorflow2 deep r...  \n",
       "67  distributional rl using tensorflow2 implementa...  \n",
       "74  prophet forecasting scale tool producing high ...  \n",
       "95  curriculum reinforcement learning curriculum l...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Samples with OOS tags\n",
    "oos_indices = df[df.tag.isin(oos_tags)].index\n",
    "df[df.tag.isin(oos_tags)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92585dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_on</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2020-02-28 23:55:26</td>\n",
       "      <td>Awesome Monte Carlo Tree Search</td>\n",
       "      <td>A curated list of Monte Carlo tree search pape...</td>\n",
       "      <td>other</td>\n",
       "      <td>awesome monte carlo tree search curated list m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>121</td>\n",
       "      <td>2020-03-24 04:56:38</td>\n",
       "      <td>Deep Reinforcement Learning in TensorFlow2</td>\n",
       "      <td>deep-rl-tf2 is a repository that implements a ...</td>\n",
       "      <td>other</td>\n",
       "      <td>deep reinforcement learning tensorflow2 deep r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>218</td>\n",
       "      <td>2020-04-06 11:29:57</td>\n",
       "      <td>Distributional RL using TensorFlow2</td>\n",
       "      <td>🐳 Implementation of various Distributional Rei...</td>\n",
       "      <td>other</td>\n",
       "      <td>distributional rl using tensorflow2 implementa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>239</td>\n",
       "      <td>2020-04-06 18:39:48</td>\n",
       "      <td>Prophet: Forecasting At Scale</td>\n",
       "      <td>Tool for producing high quality forecasts for ...</td>\n",
       "      <td>other</td>\n",
       "      <td>prophet forecasting scale tool producing high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>277</td>\n",
       "      <td>2020-04-07 00:30:33</td>\n",
       "      <td>Curriculum for Reinforcement Learning</td>\n",
       "      <td>Curriculum learning applied to reinforcement l...</td>\n",
       "      <td>other</td>\n",
       "      <td>curriculum reinforcement learning curriculum l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id           created_on                                       title  \\\n",
       "3    15  2020-02-28 23:55:26             Awesome Monte Carlo Tree Search   \n",
       "37  121  2020-03-24 04:56:38  Deep Reinforcement Learning in TensorFlow2   \n",
       "67  218  2020-04-06 11:29:57         Distributional RL using TensorFlow2   \n",
       "74  239  2020-04-06 18:39:48               Prophet: Forecasting At Scale   \n",
       "95  277  2020-04-07 00:30:33       Curriculum for Reinforcement Learning   \n",
       "\n",
       "                                          description    tag  \\\n",
       "3   A curated list of Monte Carlo tree search pape...  other   \n",
       "37  deep-rl-tf2 is a repository that implements a ...  other   \n",
       "67  🐳 Implementation of various Distributional Rei...  other   \n",
       "74  Tool for producing high quality forecasts for ...  other   \n",
       "95  Curriculum learning applied to reinforcement l...  other   \n",
       "\n",
       "                                                 text  \n",
       "3   awesome monte carlo tree search curated list m...  \n",
       "37  deep reinforcement learning tensorflow2 deep r...  \n",
       "67  distributional rl using tensorflow2 implementa...  \n",
       "74  prophet forecasting scale tool producing high ...  \n",
       "95  curriculum reinforcement learning curriculum l...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace this tag with `other`\n",
    "df.tag = df.tag.apply(lambda x: \"other\" if x in oos_tags else x)\n",
    "df.iloc[oos_indices].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8dfbdd",
   "metadata": {},
   "source": [
    "Going to restrict the mapping to only tags that are above a certain frequency threshold. \n",
    "\n",
    "The tags that don't have enough projects will not have enough samples to model their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c75adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum frequency required for a tag\n",
    "min_freq = 75\n",
    "tags = Counter(df.tag.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f433c259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc190d35e6074eeaa7fc5de00c98b4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=75, description='min_freq', max=388), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tags that just made / missed the cut\n",
    "@widgets.interact(min_freq=(0, tags.most_common()[0][1]))\n",
    "def separate_tags_by_freq(min_freq=min_freq):\n",
    "    tags_above_freq = Counter(tag for tag in tags.elements()\n",
    "                                    if tags[tag] >= min_freq)\n",
    "    tags_below_freq = Counter(tag for tag in tags.elements()\n",
    "                                    if tags[tag] < min_freq)\n",
    "    print (\"Most popular tags:\\n\", tags_above_freq.most_common(3))\n",
    "    print (\"\\nTags that just made the cut:\\n\", tags_above_freq.most_common()[-3:])\n",
    "    print (\"\\nTags that just missed the cut:\\n\", tags_below_freq.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2f9d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tags that have fewer than <min_freq> occurrences\n",
    "tags_above_freq = Counter(tag for tag in tags.elements() \n",
    "                          if (tags[tag] >= min_freq))\n",
    "df.tag = df.tag.apply(lambda tag: tag if tag in tags_above_freq else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06cd7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill None with `other`\n",
    "df.tag = df.tag.fillna(\"other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62661661",
   "metadata": {},
   "source": [
    "Traditionally, we would be applying data quality tests on our data assets before and after labeling our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f46dd5",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "Start by encoding the labels into numerical values so our models can process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5ba1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b42a4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "X = df.text.to_numpy()\n",
    "y = df.tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e3339",
   "metadata": {},
   "source": [
    "Writing our own LabelEncoder which is based on scikit-learn's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4765e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(object):\n",
    "    \"\"\"Encode labels into unique indices.\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "\n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\"class_to_index\": self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e60da845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "num_classes = len(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22581584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer-vision': 0,\n",
       " 'mlops': 1,\n",
       " 'natural-language-processing': 2,\n",
       " 'other': 3}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "055a4482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'computer-vision',\n",
       " 1: 'mlops',\n",
       " 2: 'natural-language-processing',\n",
       " 3: 'other'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.index_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26491b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode\n",
    "label_encoder.encode([\"computer-vision\", \"mlops\", \"mlops\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8c01a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer-vision', 'mlops', 'mlops']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode\n",
    "label_encoder.decode(np.array([0, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b72914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(955,)\n"
     ]
    }
   ],
   "source": [
    "# Encode all our labels\n",
    "y = label_encoder.encode(y)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494cbef",
   "metadata": {},
   "source": [
    "Many of the transformations that is going to be done on our input text features are model specific. \n",
    "\n",
    "For example, the simple baselines we may do *label* encoding → *tf-idf* while for the more involved architectures we may do label encoding → *one-hot* encoding → *embeddings*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563894d",
   "metadata": {},
   "source": [
    "#### Splitting\n",
    "\n",
    "It's time to split our dataset into three data splits for training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a465182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd23858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sizes\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da8bb7",
   "metadata": {},
   "source": [
    "For our multi-class task (each input has one label), we want to ensure that each data split has similar class distributions. We can achieve this by specifying how to stratify the split by adding the **stratify** keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7db7fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split (train)\n",
    "X_train, X_, y_train, y_ = train_test_split(\n",
    "    X, y, train_size=train_size, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b09fd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 668 (0.70)\n",
      "remaining: 287 (0.30)\n"
     ]
    }
   ],
   "source": [
    "print (f\"train: {len(X_train)} ({(len(X_train) / len(X)):.2f})\\n\"\n",
    "       f\"remaining: {len(X_)} ({(len(X_) / len(X)):.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a34d20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split (test)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_, y_, train_size=0.5, stratify=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54aed383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 668 (0.70)\n",
      "val: 143 (0.15)\n",
      "test: 144 (0.15)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: {len(X_train)} ({len(X_train)/len(X):.2f})\\n\"\n",
    "      f\"val: {len(X_val)} ({len(X_val)/len(X):.2f})\\n\"\n",
    "      f\"test: {len(X_test)} ({len(X_test)/len(X):.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e83619d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts for each class\n",
    "counts = {}\n",
    "counts[\"train_counts\"] = {tag: label_encoder.decode(y_train).count(tag) for tag in label_encoder.classes}\n",
    "counts[\"val_counts\"] = {tag: label_encoder.decode(y_val).count(tag) for tag in label_encoder.classes}\n",
    "counts[\"test_counts\"] = {tag: label_encoder.decode(y_test).count(tag) for tag in label_encoder.classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56b1b905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>computer-vision</th>\n",
       "      <th>mlops</th>\n",
       "      <th>natural-language-processing</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>249</td>\n",
       "      <td>55</td>\n",
       "      <td>272</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       computer-vision  mlops  natural-language-processing  other\n",
       "train              249     55                          272     92\n",
       "val                 53     12                           58     20\n",
       "test                54     12                           58     20"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View distributions\n",
    "pd.DataFrame({\n",
    "    \"train\": counts[\"train_counts\"],\n",
    "    \"val\": counts[\"val_counts\"],\n",
    "    \"test\": counts[\"test_counts\"]\n",
    "}).T.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f5eed",
   "metadata": {},
   "source": [
    "It's hard to compare these because our train and test proportions are different. Let's see what the distribution looks like once we balance it out. What do we need to multiply our test ratio by so that we have the same amount as our train ratio?\n",
    "\n",
    "        alpha * N(test) = N(train)\n",
    "        \n",
    "        alpha = N(train)/N(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7c12b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust counts across splits\n",
    "for k in counts[\"val_counts\"].keys():\n",
    "    counts[\"val_counts\"][k] = int(counts[\"val_counts\"][k] * \\\n",
    "        (train_size/val_size))\n",
    "for k in counts[\"test_counts\"].keys():\n",
    "    counts[\"test_counts\"][k] = int(counts[\"test_counts\"][k] * \\\n",
    "        (train_size/test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca2e0ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>computer-vision</th>\n",
       "      <th>mlops</th>\n",
       "      <th>natural-language-processing</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>249</td>\n",
       "      <td>55</td>\n",
       "      <td>272</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>247</td>\n",
       "      <td>56</td>\n",
       "      <td>270</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>252</td>\n",
       "      <td>56</td>\n",
       "      <td>270</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       computer-vision  mlops  natural-language-processing  other\n",
       "train              249     55                          272     92\n",
       "val                247     56                          270     93\n",
       "test               252     56                          270     93"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_df = pd.DataFrame({\n",
    "    \"train\": counts[\"train_counts\"],\n",
    "    \"val\": counts[\"val_counts\"],\n",
    "    \"test\": counts[\"test_counts\"]\n",
    "}).T.fillna(0)\n",
    "dist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db1f86",
   "metadata": {},
   "source": [
    "We can see how much deviance there is in our naive data splits by computing the standard deviation of each split's class counts from the mean (ideal split).\n",
    "\n",
    "\n",
    "       σ  = √(x - x̄)2/ N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "187326e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851056877051131"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard deviation\n",
    "np.mean(np.std(dist_df.to_numpy(), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebaa57f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>implementation face net tensorflow 2 0 reposit...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart version closed book qa bart version seque...</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text preprocessing python using spacy library ...</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multimodal meme classification uniter given st...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time series forecasting tensorflow js machine ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  implementation face net tensorflow 2 0 reposit...   \n",
       "1  bart version closed book qa bart version seque...   \n",
       "2  text preprocessing python using spacy library ...   \n",
       "3  multimodal meme classification uniter given st...   \n",
       "4  time series forecasting tensorflow js machine ...   \n",
       "\n",
       "                           tag  \n",
       "0              computer-vision  \n",
       "1  natural-language-processing  \n",
       "2  natural-language-processing  \n",
       "3              computer-vision  \n",
       "4                        other  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split DataFrames\n",
    "train_df = pd.DataFrame({\"text\": X_train, \"tag\": label_encoder.decode(y_train)})\n",
    "val_df = pd.DataFrame({\"text\": X_val, \"tag\": label_encoder.decode(y_val)})\n",
    "test_df = pd.DataFrame({\"text\": X_test, \"tag\": label_encoder.decode(y_test)})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3e447",
   "metadata": {},
   "source": [
    "If we had a multi-label classification task, then we would've applied iterative stratification via the skmultilearn library, which essentially splits each input into subsets (where each label is considered individually) and then it distributes the samples starting with fewest \"positive\" samples and working up to the inputs that have the most labels.\n",
    "\n",
    "__Stratified sampling is a sampling method that takes into account the existence of disjoint groups within a population and produces samples where the proportion of these groups is maintained. In single-label classification tasks, groups are differentiated based on the value of the target variable.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36a8d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import IterativeStratification\n",
    "def iterative_train_test_split(X, y, train_size):\n",
    "    \"\"\"Custom iterative train test split which \n",
    "    'maintains balanced representation with respect \n",
    "    to order-th label combinations.'\n",
    "    \"\"\"\n",
    "    stratifier = IterativeStratification(\n",
    "        n_splits=2, order=1, sample_distribution_per_fold=[1.0-train_size, train_size, ])\n",
    "    train_indices, test_indices = next(stratifier.split(X, y))\n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b6b2b",
   "metadata": {},
   "source": [
    "Iterative stratification essentially creates splits while \"trying to maintain balanced representation with respect to order-th label combinations\". We used to an __order=1__ for our iterative split which means we cared about providing representative distribution of each tag across the splits. But we can account for higher-order label relationships as well where we may care about the distribution of label combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b85654",
   "metadata": {},
   "source": [
    "#### Augmentation\n",
    "\n",
    "We'll often want to increase the size and diversity of our training data split through data augmentation. It involves using the existing samples to generate synthetic, yet realistic, examples.\n",
    "\n",
    "    It's important that we implement augmentation and data imbalance techniques after splitting our dataset so that we aren't introducing data leaks.\n",
    "\n",
    "We'll use the nlpaug library to augment our dataset and assess the quality of the generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ef8af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nlpaug==1.1.0 transformers==3.0.2 -q\n",
    "# !pip install snorkel==0.9.8 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e88e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14b29f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c makcedward nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba511b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall numpy\n",
    "# pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f8b3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5d3ad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 13:01:28.694536: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30bbafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizers and transformers\n",
    "substitution = naw.ContextualWordEmbsAug(model_path=\"distilbert-base-uncased\", action=\"substitute\")\n",
    "insertion = naw.ContextualWordEmbsAug(model_path=\"distilbert-base-uncased\", action=\"insert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fed91e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Conditional image generation using Variational Autoencoders and GANs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5419f6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conditional image capture via hierarchical autoencoders inverse filter.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substitutions\n",
    "substitution.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b1185",
   "metadata": {},
   "source": [
    "Substitution doesn't seem like a great idea for us because there are certain keywords that provide strong signal for our tags so we don't want to alter those. Also, note that these augmentations are NOT deterministic and will vary every time we run them. Let's try insertion..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41218c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['• conditional data image generation accomplished using automatic variational autoencoders and conditional gans.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insertions\n",
    "insertion.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccdd618",
   "metadata": {},
   "source": [
    "A little better but still quite fragile and now it can potentially insert key words that can influence false positive tags to appear. Maybe instead of substituting or inserting new tokens, let's try simply swapping machine learning related keywords with their aliases. We'll use Snorkel's transformation functions to easily achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e184a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38f9386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dashes from tags & aliases\n",
    "def replace_dash(x):\n",
    "    return x.replace(\"-\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e02f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aliases\n",
    "aliases_by_tag = {\n",
    "    \"computer-vision\": [\"cv\", \"vision\"],\n",
    "    \"mlops\": [\"production\"],\n",
    "    \"natural-language-processing\": [\"nlp\", \"nlproc\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a4d7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten dict\n",
    "flattened_aliases = {}\n",
    "for tag, aliases in aliases_by_tag.items():\n",
    "    tag = replace_dash(x=tag)\n",
    "    if len(aliases):\n",
    "        flattened_aliases[tag] = aliases\n",
    "    for alias in aliases:\n",
    "        _aliases = aliases + [tag]\n",
    "        _aliases.remove(alias)\n",
    "        flattened_aliases[alias] = _aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54d9406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp', 'nlproc']\n",
      "['nlproc', 'natural language processing']\n"
     ]
    }
   ],
   "source": [
    "print (flattened_aliases[\"natural language processing\"])\n",
    "print (flattened_aliases[\"nlp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b05ab",
   "metadata": {},
   "source": [
    "For now we'll use tags and aliases as they are in *aliases_by_tag* but we could account for plurality of tags using the inflect package or apply stemming before replacing aliases, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53a3fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# We want to match with the whole word only\n",
    "print (\"gan\" in \"This is a gan.\")\n",
    "print (\"gan\" in \"This is gandalf.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d02475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\b matches spaces\n",
    "def find_word(word, text):\n",
    "    word = word.replace(\"+\", \"\\+\")\n",
    "    pattern = re.compile(fr\"\\b({word})\\b\", flags=re.IGNORECASE)\n",
    "    return pattern.search(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be0ab86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(10, 13), match='gan'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Correct behavior (single instance)\n",
    "print (find_word(\"gan\", \"This is a gan.\"))\n",
    "print (find_word(\"gan\", \"This is gandalf.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f6e01",
   "metadata": {},
   "source": [
    "Now let's use snorkel's **transformation_function** to systematically apply this transformation to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "433a6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.augmentation import transformation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f80b5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "@transformation_function()\n",
    "def swap_aliases(x):\n",
    "    \"\"\"Swap ML keywords with their aliases.\"\"\" \n",
    "    # Find all matches\n",
    "    matches = []\n",
    "    for i, tag in enumerate(flattened_aliases):\n",
    "        match = find_word(tag, x.text)  \n",
    "        if match:\n",
    "            matches.append(match)\n",
    "    # Swap a random match with a random alias\n",
    "    if len(matches):\n",
    "        match = random.choice(matches)\n",
    "        tag = x.text[match.start():match.end()]\n",
    "        x.text = f\"{x.text[:match.start()]}{random.choice(flattened_aliases[tag])}{x.text[match.end():]}\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe1e57b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey reinforcement learning nlproc tasks\n",
      "survey reinforcement learning natural language processing tasks\n",
      "survey reinforcement learning nlproc tasks\n"
     ]
    }
   ],
   "source": [
    "# Swap\n",
    "for i in range(3):\n",
    "    sample_df = pd.DataFrame([{\"text\": \"a survey of reinforcement learning for nlp tasks.\"}])\n",
    "    sample_df.text = sample_df.text.apply(clean_text, lower=True, stem=False)\n",
    "    print (swap_aliases(sample_df.iloc[0]).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ac68b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autogenerate vision apply jobs using nlp\n",
      "autogenerate cv apply jobs using nlproc\n",
      "autogenerate cv apply jobs using nlproc\n"
     ]
    }
   ],
   "source": [
    "# Undesired behavior (needs contextual insight)\n",
    "for i in range(3):\n",
    "    sample_df = pd.DataFrame([{\"text\": \"Autogenerate your CV to apply for jobs using NLP.\"}])\n",
    "    sample_df.text = sample_df.text.apply(clean_text, lower=True, stem=False)\n",
    "    print (swap_aliases(sample_df.iloc[0]).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af47c02",
   "metadata": {},
   "source": [
    "Define a augmentation policy to apply our transformation functions with certain rules \n",
    "\n",
    "(how many samples to generate, whether to keep the original data point, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "411e48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.augmentation import ApplyOnePolicy, PandasTFApplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90715adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 668/668 [00:03<00:00, 209.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>implementation face net tensorflow 2 0 reposit...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart version closed book qa bart version seque...</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text preprocessing python using spacy library ...</td>\n",
       "      <td>natural-language-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multimodal meme classification uniter given st...</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time series forecasting tensorflow js machine ...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  implementation face net tensorflow 2 0 reposit...   \n",
       "1  bart version closed book qa bart version seque...   \n",
       "2  text preprocessing python using spacy library ...   \n",
       "3  multimodal meme classification uniter given st...   \n",
       "4  time series forecasting tensorflow js machine ...   \n",
       "\n",
       "                           tag  \n",
       "0              computer-vision  \n",
       "1  natural-language-processing  \n",
       "2  natural-language-processing  \n",
       "3              computer-vision  \n",
       "4                        other  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation function (TF) policy\n",
    "policy = ApplyOnePolicy(n_per_original=5, keep_original=True)\n",
    "tf_applier = PandasTFApplier([swap_aliases], policy)\n",
    "train_df_augmented = tf_applier.apply(train_df)\n",
    "train_df_augmented.drop_duplicates(subset=[\"text\"], inplace=True)\n",
    "train_df_augmented.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "741d7030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 887)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(train_df_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b405830",
   "metadata": {},
   "source": [
    "For now, we'll skip the data augmentation because it's quite fickle and empirically it doesn't improvement performance much. But we can see how this can be very effective once we can control what type of vocabulary to augment on and what exactly to augment with.\n",
    "\n",
    "    Regardless of what method we use, it's important to validate that we're not just augmenting for the sake of\n",
    "    augmentation. We can do this by executing any existing data validation tests and even creating specific tests \n",
    "    to apply on augmented data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c144af",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de6e33",
   "metadata": {},
   "source": [
    "We'll begin modeling by starting with the simplest baseline and slowly adding complexity.\n",
    "\n",
    "    The specific model we use is irrelevant since the main focus is on all the components required \n",
    "    to put a model in production and maintain it. \n",
    "    \n",
    "We'll first set up some functions that we'll be using across the different baseline experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "662a30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22f9ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d498481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, lower, stem, min_freq):\n",
    "    \"\"\"Preprocess the data.\"\"\"\n",
    "    df[\"text\"] = df.title + \" \" + df.description  # feature engineering\n",
    "    df.text = df.text.apply(clean_text, lower=lower, stem=stem)  # clean text\n",
    "\n",
    "    # Replace OOS tags with `other`\n",
    "    oos_tags = [item for item in df.tag.unique() if item not in ACCEPTED_TAGS]\n",
    "    df.tag = df.tag.apply(lambda x: \"other\" if x in oos_tags else x)\n",
    "\n",
    "    # Replace tags below min_freq with `other`\n",
    "    tags = Counter(df.tag.values)\n",
    "    tags_above_freq = Counter(tag for tag in tags.elements() \n",
    "                            if (tags[tag] >= min_freq))\n",
    "    df.tag = df.tag.apply(lambda tag: tag if tag in tags_above_freq else None)\n",
    "    df.tag = df.tag.fillna(\"other\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "575b2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(X, y, train_size=0.7):\n",
    "    \"\"\"Generate balanced data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(\n",
    "        X, y, train_size=train_size, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed30f86",
   "metadata": {},
   "source": [
    "Our dataset is small so we'll train using the whole dataset but for larger datasets, we should always test on a small subset (after shuffling when necessary) so we aren't wasting time on compute.\n",
    "\n",
    "    **df = df.sample(frac=1).reset_index(drop=True)  # shuffle**\n",
    "    **df = df[: num_samples]  # None = all samples**\n",
    "\n",
    "**Why is it important that we shuffle our data?**\n",
    "\n",
    "We need to shuffle our data since our data is chronologically organized. The latest projects may have certain features or tags that are prevalent compared to earlier projects. If we don't shuffle before creating our data splits, then our model will only be trained on the earlier signals and fail to generalize. However, in other scenarios (ex. time-series forecasting), shuffling will lead do data leaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303393e8",
   "metadata": {},
   "source": [
    "### Baselines\n",
    "We're going to develop a model that can consume input signals and predict the appropriate classes. We'll start with simple baseline models and slowly add and motivate complexity.\n",
    "\n",
    "#### Random\n",
    "\n",
    "_motivation_: We want to know what random (chance) performance looks like. All of our efforts should be well above this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bfb3a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2a60cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "set_seeds()\n",
    "df = pd.read_csv(\"labeled_projects.csv\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = preprocess(df, lower=True, stem=False, min_freq=min_freq)\n",
    "label_encoder = LabelEncoder().fit(df.tag)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "    get_data_splits(X=df.text.to_numpy(), y=label_encoder.encode(df.tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f560f7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LabelEncoder(num_classes=4)>\n",
      "['computer-vision', 'mlops', 'natural-language-processing', 'other']\n"
     ]
    }
   ],
   "source": [
    "# Label encoder\n",
    "print (label_encoder)\n",
    "print (label_encoder.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2668e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n",
      "[2 2 1 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Generate random predictions\n",
    "y_pred = np.random.randint(low=0, high=len(label_encoder), size=len(y_test))\n",
    "print (y_pred.shape)\n",
    "print (y_pred[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5df27892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.2844744487889649,\n",
      "  \"recall\": 0.22916666666666666,\n",
      "  \"f1\": 0.24552884283001275\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7f109",
   "metadata": {},
   "source": [
    "We made the assumption that there is an equal probability for every class. Let's use the train split to figure out what the true probability is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6f4326ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.375, 0.08333333333333333, 0.4027777777777778, 0.1388888888888889]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class frequencies\n",
    "p = [Counter(y_test)[index]/len(y_test) for index in range(len(label_encoder))]\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5f91af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate weighted random predictions\n",
    "y_pred = np.random.choice(a=range(len(label_encoder)), size=len(y_test), p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58bcd380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.3294211281499417,\n",
      "  \"recall\": 0.3194444444444444,\n",
      "  \"f1\": 0.3239553132352485\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19549b44",
   "metadata": {},
   "source": [
    "limitations: we didn't use the tokens in our input to affect our predictions so nothing was learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eff510",
   "metadata": {},
   "source": [
    "#### Rule-based\n",
    "\n",
    "motivation: we want to use signals in our inputs (along with domain expertise and auxiliary data) to determine the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4ac4847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "set_seeds()\n",
    "df = pd.read_csv(\"labeled_projects.csv\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = preprocess(df, lower=True, stem=False, min_freq=min_freq)\n",
    "label_encoder = LabelEncoder().fit(df.tag)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "    get_data_splits(X=df.text.to_numpy(), y=label_encoder.encode(df.tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ec42f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(text, aliases_by_tag):\n",
    "    \"\"\"If a token matches an alias, \n",
    "    then add the corresponding tag class.\"\"\"\n",
    "    for tag, aliases in aliases_by_tag.items():\n",
    "        if replace_dash(tag) in text:\n",
    "            return tag\n",
    "        for alias in aliases:\n",
    "            if alias in text:\n",
    "                return tag\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1542a859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural-language-processing'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "text = \"A pretrained model hub for popular nlp models.\"\n",
    "get_tag(text=clean_text(text), aliases_by_tag=aliases_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b360cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "tags = []\n",
    "for text in X_test:\n",
    "    tag = get_tag(text, aliases_by_tag=aliases_by_tag)\n",
    "    tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bd330341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "y_pred = [label_encoder.class_to_index[tag] if tag is not None else -1 for tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c23c635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8611111111111112,\n",
      "  \"recall\": 0.1597222222222222,\n",
      "  \"f1\": 0.2600750175139683\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1a3d46",
   "metadata": {},
   "source": [
    "**Why is recall so low?** \n",
    "\n",
    "Only relying on the aliases can prove catastrophic when those particular aliases aren't used in our input signals. \n",
    "\n",
    "To improve this, we can build a bag of words of related terms. \n",
    "\n",
    "For example, mapping terms such as _text classification_ and named _entity recognition_ to the _natural-language-processing_ tag but building this is a non-trivial task. \n",
    "\n",
    "Not to mention, we'll need to keep updating these rules as the data landscape matures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08ed04e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Pitfalls\n",
    "text = \"Transfer learning with transformers for text classification.\"\n",
    "print (get_tag(text=clean_text(text), aliases_by_tag=aliases_by_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8a625",
   "metadata": {},
   "source": [
    "We could also use stemming to further refine our rule-based process:\n",
    "\n",
    "        from nltk.stem import PorterStemmer\n",
    "        stemmer = PorterStemmer()\n",
    "        print (stemmer.stem(\"democracy\"))\n",
    "        print (stemmer.stem(\"democracies\"))\n",
    "        democraci\n",
    "        democraci\n",
    "\n",
    "But these rule-based approaches can only yield labels with high certainty when there is an absolute condition match so it's best not to spend too much more effort on this approach.\n",
    "\n",
    "limitations: we failed to generalize or learn any implicit patterns to predict the labels because we treat the tokens in our input as isolated entities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcee12c",
   "metadata": {},
   "source": [
    "#### Vectorization\n",
    "\n",
    "_motivation_:\n",
    "\n",
    "    representation: use term frequency-inverse document frequency (TF-IDF) to capture the significance of a token to a particular input with respect to all the inputs, as opposed to treating the words in our input text as isolated tokens.\n",
    "    \n",
    "    architecture: we want our model to meaningfully extract the encoded signal to predict the output labels.\n",
    "\n",
    "So far we've treated the words in our input text as isolated tokens and we haven't really captured any meaning between tokens. Let's use TF-IDF (via scikit-learn's TfidfVectorizer) to capture the significance of a token to a particular input with respect to all the inputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "91dabe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "03054587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "set_seeds()\n",
    "df = pd.read_csv(\"labeled_projects.csv\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = preprocess(df, lower=True, stem=False, min_freq=min_freq)\n",
    "label_encoder = LabelEncoder().fit(df.tag)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "    get_data_splits(X=df.text.to_numpy(), y=label_encoder.encode(df.tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5ea1ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving raw X_test to compare with later\n",
    "X_test_raw = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "205aaa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laplacian pyramid reconstruction refinement semantic seg pytorch implementation multi resolution reconstruction architecture based laplacian pyramid uses skip connections\n",
      "(668, 98496)\n"
     ]
    }
   ],
   "source": [
    "# Tf-idf\n",
    "vectorizer = TfidfVectorizer(analyzer=\"char\", ngram_range=(2,7))  # char n-grams\n",
    "print (X_train[0])\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "print (X_train.shape)  # scipy.sparse.csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd6719ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts: [249  55 272  92],\n",
      "class weights: {0: 0.004016064257028112, 1: 0.01818181818181818, 2: 0.003676470588235294, 3: 0.010869565217391304}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"class counts: {counts},\\nclass weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b65061",
   "metadata": {},
   "source": [
    "#### Data imbalance\n",
    "\n",
    "With our datasets, we may often notice a data imbalance problem where a range of continuous values (regression) or certain classes (classification) may have insufficient amounts of data to learn from. This becomes a major issue when training because the model will learn to generalize to the data available and perform poorly on regions where the data is sparse. There are several techniques to mitigate data imbalance, including resampling, incorporating class weights, augmentation, etc. Though the ideal solution is to collect more data for the minority classes!\n",
    "\n",
    "    use the imblearn package to ensure that we oversample our minority classes to be equal to the majority class \n",
    "    (tag with most samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1a7d1a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# !pip install imbalanced-learn==0.8.1 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bcc66f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1abbbe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample (training set)\n",
    "oversample = RandomOverSampler(sampling_strategy=\"all\")\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513ea2d",
   "metadata": {},
   "source": [
    "It's important that we applied sampling only on the train split so we don't introduce data leaks with the other data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e83e1e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts: [272 272 272 272],\n",
      "class weights: {0: 0.003676470588235294, 1: 0.003676470588235294, 2: 0.003676470588235294, 3: 0.003676470588235294}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_over)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"class counts: {counts},\\nclass weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3785a5a",
   "metadata": {},
   "source": [
    "#### Machine learning\n",
    "\n",
    "Use a stochastic gradient descent classifier (SGDClassifier) as our model. We're going to use log loss so that it's effectively logistic regression with SGD.\n",
    "\n",
    "    We're doing this because we want to have more control over the training process (epochs) \n",
    "    and not use scikit-learn's default second order optimization methods \n",
    "    (ex. LGBFS) for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "817f8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f3647427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SGDClassifier(\n",
    "    loss=\"log\", penalty=\"l2\", alpha=1e-4, max_iter=1,\n",
    "    learning_rate=\"constant\", eta0=1e-1, power_t=0.1, \n",
    "    warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "09ddc170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 | train_loss: 1.16783, val_loss: 1.20177\n",
      "Epoch: 10 | train_loss: 0.46262, val_loss: 0.62612\n",
      "Epoch: 20 | train_loss: 0.31599, val_loss: 0.51986\n",
      "Epoch: 30 | train_loss: 0.25191, val_loss: 0.47544\n",
      "Epoch: 40 | train_loss: 0.21720, val_loss: 0.45176\n",
      "Epoch: 50 | train_loss: 0.19610, val_loss: 0.43770\n",
      "Epoch: 60 | train_loss: 0.18221, val_loss: 0.42857\n",
      "Epoch: 70 | train_loss: 0.17291, val_loss: 0.42246\n",
      "Epoch: 80 | train_loss: 0.16643, val_loss: 0.41818\n",
      "Epoch: 90 | train_loss: 0.16160, val_loss: 0.41528\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.fit(X_over, y_over)\n",
    "\n",
    "    # Evaluation\n",
    "    train_loss = log_loss(y_train, model.predict_proba(X_train))\n",
    "    val_loss = log_loss(y_val, model.predict_proba(X_val))\n",
    "\n",
    "    if not epoch%10:\n",
    "        print(\n",
    "            f\"Epoch: {epoch:02d} | \"\n",
    "            f\"train_loss: {train_loss:.5f}, \"\n",
    "            f\"val_loss: {val_loss:.5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab18ab",
   "metadata": {},
   "source": [
    "We could further optimize our training pipeline with functionality such as early stopping where we would use our validation set that we created. But we want to keep this model-agnostic course simplified during the modeling stage.\n",
    "\n",
    "    The SGDClassifier has an _early_stopping_ flag where you can specify a portion of the training \n",
    "    set to be use for validation. Why would this be a bad idea in our case? \n",
    "    Because we already applied oversampling in our training set and so we would be \n",
    "    introduce data leaks if we did this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "04527d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.8895157525375742,\n",
      "  \"recall\": 0.8888888888888888,\n",
      "  \"f1\": 0.887320081070081\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7c051",
   "metadata": {},
   "source": [
    "Scikit-learn has a concept called pipeline which allows us to combine transformations and training steps into one callable function.\n",
    "\n",
    "We can create a pipeline from scratch:\n",
    "\n",
    "    '# Create pipeline from scratch'\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    steps = (\n",
    "        (\"tfidf\", TfidfVectorizer(analyzer=\"char\", ngram_range=(2,7))), \n",
    "        (\"model\", SGDClassifier(\n",
    "            loss=\"log\", penalty=\"l2\", alpha=1e-4, max_iter=1,\n",
    "            learning_rate=\"constant\", eta0=1e-1, power_t=0.1, \n",
    "            warm_start=True)))\n",
    "    pipe = Pipeline(steps)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "or make one with trained components:\n",
    "\n",
    "    '# Make pipeline from existing components'\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    pipe = make_pipeline(vectorizer, model)\n",
    "\n",
    "limitations:\n",
    "\n",
    "    representation: TF-IDF representations don't encapsulate much signal beyond frequency \n",
    "    but we require more fine-grained token representations that can account for \n",
    "    the significance of the token itself (embeddings).\n",
    "\n",
    "    architecture: we want to develop models that can use better represented encodings \n",
    "    in a more contextual manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "36c75e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural-language-processing']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference (with tokens similar to training data)\n",
    "text = \"Transfer learning with transformers for text classification.\"\n",
    "y_pred = model.predict(vectorizer.transform([text]))\n",
    "label_encoder.decode(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f7181a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer-vision': 0.032693612917747666,\n",
       " 'mlops': 0.0034124378175269276,\n",
       " 'natural-language-processing': 0.9525596587621376,\n",
       " 'other': 0.01133429050258778}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities\n",
    "y_prob = model.predict_proba(vectorizer.transform([text]))\n",
    "{tag:y_prob[0][i] for i, tag in enumerate(label_encoder.classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97ac066e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural-language-processing']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference (with tokens not similar to training data)\n",
    "text = \"Interpretability methods for explaining model behavior.\"\n",
    "y_pred = model.predict(vectorizer.transform([text]))\n",
    "label_encoder.decode(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fd2b9445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer-vision': 0.1558952586187617,\n",
       " 'mlops': 0.1019907952880464,\n",
       " 'natural-language-processing': 0.6498181711246134,\n",
       " 'other': 0.0922957749685785}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities\n",
    "y_prob = model.predict_proba(vectorizer.transform([text]))\n",
    "{tag:y_prob[0][i] for i, tag in enumerate(label_encoder.classes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d672ab7",
   "metadata": {},
   "source": [
    "We're going to create a custom predict function where if the majority class is not above a certain softmax score, then we predict the _other_ class. In our objectives, we decided that precision is really important for us and that we can leverage the labeling and QA workflows to improve the recall during subsequent manual inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69548e0",
   "metadata": {},
   "source": [
    "Our models can suffer from overconfidence so applying this limitation may not be as effective as we'd imagine, especially for larger neural networks. See the confident learning section of the evaluation lesson for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2d0f93b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6742890218960005"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine first quantile softmax score for the correct class (on validation split)\n",
    "y_pred = model.predict(X_val)\n",
    "y_prob = model.predict_proba(X_val)\n",
    "threshold = np.quantile([y_prob[i][j] for i, j in enumerate(y_pred)], q=0.25)  # Q1\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dda271",
   "metadata": {},
   "source": [
    "It's very important that we do this on our validation split so we aren't inflating the value using the train split or leaking information prior to evaluation on the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e8bb2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom predict function\n",
    "def custom_predict(y_prob, threshold, index):\n",
    "    \"\"\"Custom predict function that defaults \n",
    "    to an index if conditions are not met.\"\"\"\n",
    "    y_pred = [np.argmax(p) if max(p) > threshold else index for p in y_prob]\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8f338e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tag(texts):\n",
    "    y_prob = model.predict_proba(vectorizer.transform(texts))\n",
    "    other_index = label_encoder.class_to_index[\"other\"]\n",
    "    y_pred = custom_predict(y_prob=y_prob, threshold=threshold, index=other_index)\n",
    "    return label_encoder.decode(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dea25e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['other']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference (with tokens not similar to training data)\n",
    "text = \"Interpretability methods for explaining model behavior.\"\n",
    "predict_tag(texts=[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "838805e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9116161616161617,\n",
      "  \"recall\": 0.7569444444444444,\n",
      "  \"f1\": 0.7929971988795519\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_prob = model.predict_proba(X_test)\n",
    "y_pred = custom_predict(y_prob=y_prob, threshold=threshold, index=label_encoder.class_to_index[\"other\"])\n",
    "metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "performance = {\"precision\": metrics[0], \"recall\": metrics[1], \"f1\": metrics[2]}\n",
    "print (json.dumps(performance, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a95095",
   "metadata": {},
   "source": [
    "We could've even used per-class thresholds, especially since we have some data imbalance which can impact how confident the model is regarding some classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d882ea",
   "metadata": {},
   "source": [
    "    y_pred = model.predict(X_val)\n",
    "    y_prob = model.predict_proba(X_val)\n",
    "    class_thresholds = {}\n",
    "    for index in range(len(label_encoder.classes)):\n",
    "        class_thresholds[index] = np.mean(\n",
    "            [y_prob[i][index] for i in np.where(y_pred==index)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4aede5",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "This is actually model-agnostic (as long as it produces probability distributions) so feel free to use more complex representations (embeddings) with more sophisticated architectures (CNNs, transformers, etc.). \n",
    "\n",
    "We're going to use this basic logistic regression model throughout the rest of the lessons because it's easy, fast and actually has comparable performance (<10% f1 diff compared to SOTA pretrained transformers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35418dd",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "So far we've been evaluating our models by determing the overall precision, recall and f1 scores. But since performance is one of the key decision making factors when comparing different models, we should have even more nuanced evaluation strategies.\n",
    "\n",
    "    * Coarse-grained metrics\n",
    "    * Fine-grained metrics\n",
    "    * Confusion matrix\n",
    "    * Confidence learning\n",
    "    * Slice metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "78ab6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "metrics = {\"overall\": {}, \"class\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5ca9439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to evaluate\n",
    "other_index = label_encoder.class_to_index[\"other\"]\n",
    "y_prob = model.predict_proba(X_test)\n",
    "y_pred = custom_predict(y_prob=y_prob, threshold=threshold, index=other_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5d42e",
   "metadata": {},
   "source": [
    "#### Coarse-grained metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "54157a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"precision\": 0.9116161616161617,\n",
      "    \"recall\": 0.7569444444444444,\n",
      "    \"f1\": 0.7929971988795519,\n",
      "    \"num_samples\": 144.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Overall metrics\n",
    "overall_metrics = precision_recall_fscore_support(y_test, y_pred, average=\"weighted\")\n",
    "metrics[\"overall\"][\"precision\"] = overall_metrics[0]\n",
    "metrics[\"overall\"][\"recall\"] = overall_metrics[1]\n",
    "metrics[\"overall\"][\"f1\"] = overall_metrics[2]\n",
    "metrics[\"overall\"][\"num_samples\"] = np.float64(len(y_test))\n",
    "print (json.dumps(metrics[\"overall\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e046c4",
   "metadata": {},
   "source": [
    "#### Fine-grained metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "712bef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e84032f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class metrics\n",
    "class_metrics = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "for i, _class in enumerate(label_encoder.classes):\n",
    "    metrics[\"class\"][_class] = {\n",
    "        \"precision\": class_metrics[0][i],\n",
    "        \"recall\": class_metrics[1][i],\n",
    "        \"f1\": class_metrics[2][i],\n",
    "        \"num_samples\": np.float64(class_metrics[3][i]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4e04fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 1.0,\n",
      "  \"recall\": 0.7586206896551724,\n",
      "  \"f1\": 0.8627450980392156,\n",
      "  \"num_samples\": 58.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Metrics for a specific class\n",
    "tag = \"natural-language-processing\"\n",
    "print (json.dumps(metrics[\"class\"][tag], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a87961fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"natural-language-processing\",\n",
      "  {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.7586206896551724,\n",
      "    \"f1\": 0.8627450980392156,\n",
      "    \"num_samples\": 58.0\n",
      "  }\n",
      "]\n",
      "[\n",
      "  \"mlops\",\n",
      "  {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.75,\n",
      "    \"f1\": 0.8571428571428571,\n",
      "    \"num_samples\": 12.0\n",
      "  }\n",
      "]\n",
      "[\n",
      "  \"computer-vision\",\n",
      "  {\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.6666666666666666,\n",
      "    \"f1\": 0.8,\n",
      "    \"num_samples\": 54.0\n",
      "  }\n",
      "]\n",
      "[\n",
      "  \"other\",\n",
      "  {\n",
      "    \"precision\": 0.36363636363636365,\n",
      "    \"recall\": 1.0,\n",
      "    \"f1\": 0.5333333333333333,\n",
      "    \"num_samples\": 20.0\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Sorted tags\n",
    "sorted_tags_by_f1 = OrderedDict(sorted(\n",
    "        metrics[\"class\"].items(), key=lambda tag: tag[1][\"f1\"], reverse=True))\n",
    "for item in sorted_tags_by_f1.items():\n",
    "    print (json.dumps(item, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9f919",
   "metadata": {},
   "source": [
    "Due to our custom predict function, we're able to achieve high precision for the categories except for other. \n",
    "\n",
    "Based on our product design, we decided that it's more important to be precise about our explicit ML categories (nlp, cv, and mlops) and that we would have a manual labeling workflow to recall any misclassifications in the other category. \n",
    "\n",
    "Overtime, our model will become better in this category as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea2e01",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "**True positives (TP)**: learn about where our model performs well.\n",
    "\n",
    "**False positives (FP)**: potentially identify samples which may need to be relabeled.\n",
    "\n",
    "**False negatives (FN)**: identify the model's less performant areas to oversample later.\n",
    "\n",
    "It's a good to have our FP/FN samples feed back into our annotation pipelines in the event we want to fix their labels and have those changes be reflected everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e5bd2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP, FP, FN samples\n",
    "tag = \"mlops\"\n",
    "index = label_encoder.class_to_index[tag]\n",
    "tp, fp, fn = [], [], []\n",
    "for i, true in enumerate(y_test):\n",
    "    pred = y_pred[i]\n",
    "    if index==true==pred:\n",
    "        tp.append(i)\n",
    "    elif index!=true and index==pred:\n",
    "        fp.append(i)\n",
    "    elif index==true and index!=pred:\n",
    "        fn.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1ea5c087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 47, 52, 96, 111, 123, 129, 141]\n",
      "[]\n",
      "[38, 130, 136]\n"
     ]
    }
   ],
   "source": [
    "print (tp)\n",
    "print (fp)\n",
    "print (fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bc7640cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytest pytest framework makes easy write small tests yet scales support complex functional testing\n",
      "true: mlops\n",
      "pred: mlops\n"
     ]
    }
   ],
   "source": [
    "index = tp[0]\n",
    "print (X_test_raw[index])\n",
    "print (f\"true: {label_encoder.decode([y_test[index]])[0]}\")\n",
    "print (f\"pred: {label_encoder.decode([y_pred[index]])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "63ff4c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27112b84f5034e8288ab2cf3119f7eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='tag', index=1, options=('natural-language-processing', 'mlops', 'c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(tag=list(sorted_tags_by_f1.keys()))\n",
    "def display_tag_analysis(tag=\"mlops\"):\n",
    "    # Performance\n",
    "    print (json.dumps(metrics[\"class\"][tag], indent=2))\n",
    "\n",
    "    # TP, FP, FN samples\n",
    "    index = label_encoder.class_to_index[tag]\n",
    "    tp, fp, fn = [], [], []\n",
    "    for i, true in enumerate(y_test):\n",
    "        pred = y_pred[i]\n",
    "        if index==true==pred:\n",
    "            tp.append(i)\n",
    "        elif index!=true and index==pred:\n",
    "            fp.append(i)\n",
    "        elif index==true and index!=pred:\n",
    "            fn.append(i)\n",
    "\n",
    "    # Samples\n",
    "    num_samples = 3\n",
    "    cm = [(tp, \"True positives\"), (fp, \"False positives\"), (fn, \"False negatives\")]\n",
    "    for item in cm:\n",
    "        if len(item[0]):\n",
    "            print (f\"\\n=== {item[1]} ===\")\n",
    "            for index in item[0][:num_samples]:\n",
    "                print (f\"  {X_test_raw[index]}\")\n",
    "                print (f\"    true: {label_encoder.decode([y_test[index]])[0]}\")\n",
    "                print (f\"    pred: {label_encoder.decode([y_pred[index]])[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c5c8d",
   "metadata": {},
   "source": [
    "It's a really good idea to do this kind of analysis using our rule-based approach to catch really obvious labeling errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3959df",
   "metadata": {},
   "source": [
    "### Confidence learning\n",
    "\n",
    "While the confusion-matrix sample analysis was a coarse-grained process, we can also use fine-grained confidence based approaches to identify potentially mislabeled samples. Here we’re going to focus on the specific labeling quality as opposed to the final model predictions.\n",
    "\n",
    "Simple confidence based techniques include identifying samples whose:\n",
    "\n",
    "#### Categorical\n",
    "\n",
    "    prediction is incorrect (also indicate TN, FP, FN)\n",
    "    confidence score for the correct class is below a threshold\n",
    "    confidence score for an incorrect class is above a threshold\n",
    "    standard deviation of confidence scores over top N samples is low\n",
    "    different predictions from same model using different parameters\n",
    "\n",
    "#### Continuous\n",
    "\n",
    "    difference between predicted and ground-truth values is above some %\n",
    "    \n",
    "\n",
    "The operations in this section can be applied to entire labeled dataset to discover labeling errors via confidence learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "85d94a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,)\n",
      "(144, 4)\n"
     ]
    }
   ],
   "source": [
    "# y\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print (np.shape(y_test))\n",
    "print (np.shape(y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ba01d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to show raw text\n",
    "test_df = pd.DataFrame({\"text\": X_test_raw, \"tag\": label_encoder.decode(y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dafb198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag to inspect\n",
    "tag = \"mlops\"\n",
    "index = label_encoder.class_to_index[tag]\n",
    "indices = np.where(y_test==index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3d11b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence score for the correct class is below a threshold\n",
    "low_confidence = []\n",
    "min_threshold = 0.5\n",
    "for i in indices:\n",
    "    prob = y_prob[i][index]\n",
    "    if prob <= 0.5:\n",
    "        low_confidence.append({\"text\": test_df.text[i], \n",
    "                               \"true\": label_encoder.index_to_class[y_test[i]], \n",
    "                               \"pred\": label_encoder.index_to_class[y_pred[i]], \n",
    "                               \"prob\": prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7281584e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'neptune ai lightweight experiment management tool fits workflow',\n",
       "  'true': 'mlops',\n",
       "  'pred': 'other',\n",
       "  'prob': 0.41281721056332793}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_confidence[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1d966",
   "metadata": {},
   "source": [
    "But these are fairly crude techniques because neural networks are easily overconfident and so their confidences cannot be used without calibrating them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f37fb5",
   "metadata": {},
   "source": [
    "Modern (large) neural networks result in higher accuracies but are over confident.\n",
    "On Calibration of Modern Neural Networks\n",
    "\n",
    "   **Assumption**: “the probability associated with the predicted class label should reflect its ground truth correctness likelihood.”\n",
    "\n",
    "   **Reality**: “modern (large) neural networks are no longer well-calibrated”\n",
    "\n",
    "   **Solution**: apply temperature scaling (extension of Platt scaling{:target=\"_blank\"}) on model outputs\n",
    "\n",
    "Recent work on confident learning focuses on identifying noisy labels while accounting for this overconfidence which can then be properly relabeled and used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d6fdc3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# !pip install cleanlab==1.0.1 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "af744493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleanlab\n",
    "from cleanlab.pruning import get_noise_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7d73175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Determine potential labeling errors\n",
    "label_error_indices = get_noise_indices(\n",
    "            s=y_test, \n",
    "            psx=y_prob,\n",
    "            sorted_index_method=\"self_confidence\",\n",
    "            verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e33b1",
   "metadata": {},
   "source": [
    "Not all of these are necessarily labeling errors but situations where the predicted probabilities were not so confident. Therefore, it will be useful to attach the predicted outcomes along side results. This way, we can know if we need to relabel, upsample, etc. as mitigation strategies to improve our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1d602812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: module 2 convolutional neural networks cs231n lecture 5 move fully connected neural networks convolutional neural networks\n",
      "true: computer-vision\n",
      "pred: other\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = 5\n",
    "for index in label_error_indices[:num_samples]:\n",
    "    print (\"text:\", test_df.iloc[index].text)\n",
    "    print (\"true:\", test_df.iloc[index].tag)\n",
    "    print (\"pred:\", label_encoder.decode([y_pred[index]])[0])\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e3eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
